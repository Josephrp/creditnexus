"""API routes for credit agreement extraction."""

import logging
import io
import json
from datetime import datetime, date
from decimal import Decimal
from typing import Optional, List, Dict, Any
from fastapi import APIRouter, HTTPException, UploadFile, File, Depends, Query, Request
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session, joinedload
import pandas as pd

from app.chains.extraction_chain import extract_data, extract_data_smart
from app.models.cdm import ExtractionResult, CreditAgreement
from app.db import get_db
from app.db.models import StagedExtraction, ExtractionStatus, Document, DocumentVersion, Workflow, WorkflowState, User, AuditLog, AuditAction, PolicyDecision as PolicyDecisionModel
from app.auth.jwt_auth import get_current_user, require_auth
from app.services.policy_service import PolicyService
from app.services.x402_payment_service import X402PaymentService
from fastapi import Request

logger = logging.getLogger(__name__)

# Deep Tech Components (Loaded on startup)
from app.agents.classifier import LandUseClassifier
from app.models.cdm_events import generate_cdm_trade_execution, generate_cdm_observation, generate_cdm_terms_change
from app.agents.vector_store import GLOBAL_VECTOR_STORE
import hashlib

# Initialize TorchGeo Classifier (Loads ResNet50 Weights)
# This might take a few seconds on first run
GLOBAL_CLASSIFIER = LandUseClassifier()


def log_audit_action(
    db: Session,
    action: AuditAction,
    target_type: str,
    target_id: Optional[int] = None,
    user_id: Optional[int] = None,
    metadata: Optional[dict] = None,
    request: Optional[Request] = None
) -> AuditLog:
    """Log an audit action to the database.
    
    Args:
        db: Database session.
        action: The type of action being logged.
        target_type: The type of entity being acted upon (e.g., 'document', 'workflow').
        target_id: The ID of the target entity.
        user_id: The ID of the user performing the action.
        metadata: Additional context data for the action.
        request: The HTTP request (to extract IP and user agent).
        
    Returns:
        The created AuditLog record.
    """
    ip_address = None
    user_agent = None
    
    if request:
        forwarded = request.headers.get("x-forwarded-for")
        if forwarded:
            ip_address = forwarded.split(",")[0].strip()
        else:
            ip_address = request.client.host if request.client else None
        user_agent = request.headers.get("user-agent", "")[:500]
    
    audit_log = AuditLog(
        user_id=user_id,
        action=action.value,
        target_type=target_type,
        target_id=target_id,
        action_metadata=metadata,
        ip_address=ip_address,
        user_agent=user_agent,
    )
    db.add(audit_log)
    return audit_log


def get_policy_service(request: Request) -> Optional[PolicyService]:
    """
    Get policy service instance from application state.
    
    This dependency function provides access to the PolicyService instance
    that was initialized at application startup. Returns None if policy
    engine is disabled.
    
    Args:
        request: FastAPI request object (to access app.state)
        
    Returns:
        PolicyService instance or None if disabled
    """
    if hasattr(request.app.state, 'policy_service'):
        return request.app.state.policy_service
    return None


def get_x402_payment_service(request: Request) -> Optional[X402PaymentService]:
    """
    Get x402 payment service instance from application state.
    
    This dependency function provides access to the X402PaymentService instance
    that was initialized at application startup. Returns None if x402
    payment service is disabled.
    
    Args:
        request: FastAPI request object (to access app.state)
        
    Returns:
        X402PaymentService instance or None if disabled
    """
    if hasattr(request.app.state, 'x402_payment_service'):
        return request.app.state.x402_payment_service
    return None


MAX_FILE_SIZE_MB = 20

def extract_text_from_pdf(file_content: bytes) -> str:
    """Extract text from a PDF file using PyMuPDF.
    
    Args:
        file_content: The raw bytes of the PDF file.
        
    Returns:
        Extracted text from all pages.
    """
    import fitz
    
    file_size_mb = len(file_content) / (1024 * 1024)
    if file_size_mb > MAX_FILE_SIZE_MB:
        raise ValueError(f"File too large ({file_size_mb:.1f} MB). Maximum size is {MAX_FILE_SIZE_MB} MB.")
    
    doc = None
    text_parts = []
    try:
        doc = fitz.open(stream=file_content, filetype="pdf")
        for page in doc:
            text_parts.append(page.get_text())
    except Exception as e:
        logger.error(f"Error extracting text from PDF: {e}")
        raise ValueError(f"Failed to parse PDF file: {str(e)}")
    finally:
        if doc:
            doc.close()
    
    return "\n".join(text_parts)

router = APIRouter(prefix="/api")


class ExtractionRequest(BaseModel):
    """Request model for credit agreement extraction."""
    text: str = Field(..., description="The raw text content of a credit agreement document")
    force_map_reduce: bool = Field(False, description="Force map-reduce extraction strategy for large documents")


@router.post("/extract")
async def extract_credit_agreement(
    request: ExtractionRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
    policy_service: Optional[PolicyService] = Depends(get_policy_service)
):
    """Extract structured data from a credit agreement document.
    
    Args:
        request: ExtractionRequest containing the document text and options.
        db: Database session for audit logging.
        current_user: Current authenticated user.
        policy_service: Policy service for compliance evaluation (optional).
        
    Returns:
        Extraction result with status, agreement data, policy decision, and optional message.
    """
    from app.models.cdm import ExtractionStatus
    from app.db.models import PolicyDecision as PolicyDecisionModel
    from app.models.cdm_events import generate_cdm_policy_evaluation
    
    try:
        logger.info(f"Received extraction request for {len(request.text)} characters")
        
        result = extract_data_smart(
            text=request.text,
            force_map_reduce=request.force_map_reduce
        )
        
        if result is None:
            raise HTTPException(
                status_code=422,
                detail={"status": "error", "message": "Extraction returned no data"}
            )
        
        if result.status == ExtractionStatus.FAILURE:
            raise HTTPException(
                status_code=422,
                detail={"status": "irrelevant_document", "message": result.message or "This document does not appear to be a credit agreement."}
            )
        
        # Policy evaluation (if enabled and agreement extracted)
        policy_decision = None
        policy_evaluation_event = None
        
        if policy_service and result.agreement:
            try:
                # Evaluate facility creation for compliance
                policy_result = policy_service.evaluate_facility_creation(
                    credit_agreement=result.agreement,
                    document_id=None  # No document ID yet at extraction stage
                )
                
                # Create CDM PolicyEvaluation event
                policy_evaluation_event = generate_cdm_policy_evaluation(
                    transaction_id=result.agreement.deal_id or result.agreement.loan_identification_number or "unknown",
                    transaction_type="facility_creation",
                    decision=policy_result.decision,
                    rule_applied=policy_result.rule_applied,
                    related_event_identifiers=[],
                    evaluation_trace=policy_result.trace,
                    matched_rules=policy_result.matched_rules
                )
                
                # Handle BLOCK decision - prevent workflow progression
                if policy_result.decision == "BLOCK":
                    logger.warning(
                        f"Policy evaluation BLOCKED facility creation: "
                        f"rule={policy_result.rule_applied}, trace_id={policy_result.trace_id}"
                    )
                    
                    # Log policy decision to audit trail
                    policy_decision_db = PolicyDecisionModel(
                        transaction_id=result.agreement.deal_id or result.agreement.loan_identification_number or "unknown",
                        transaction_type="facility_creation",
                        decision=policy_result.decision,
                        rule_applied=policy_result.rule_applied,
                        trace_id=policy_result.trace_id,
                        trace=policy_result.trace,
                        matched_rules=policy_result.matched_rules,
                        metadata={"document_extraction": True},
                        cdm_events=[policy_evaluation_event],
                        user_id=current_user.id if current_user else None
                    )
                    db.add(policy_decision_db)
                    db.commit()
                    
                    raise HTTPException(
                        status_code=403,
                        detail={
                            "status": "blocked",
                            "reason": policy_result.rule_applied,
                            "trace_id": policy_result.trace_id,
                            "message": f"Facility creation blocked by compliance policy: {policy_result.rule_applied}",
                            "cdm_event": policy_evaluation_event
                        }
                    )
                
                # Handle FLAG decision - allow but mark for review
                elif policy_result.decision == "FLAG":
                    logger.info(
                        f"Policy evaluation FLAGGED facility creation: "
                        f"rule={policy_result.rule_applied}, trace_id={policy_result.trace_id}"
                    )
                    
                    # Log policy decision to audit trail
                    policy_decision_db = PolicyDecisionModel(
                        transaction_id=result.agreement.deal_id or result.agreement.loan_identification_number or "unknown",
                        transaction_type="facility_creation",
                        decision=policy_result.decision,
                        rule_applied=policy_result.rule_applied,
                        trace_id=policy_result.trace_id,
                        trace=policy_result.trace,
                        matched_rules=policy_result.matched_rules,
                        metadata={"document_extraction": True, "requires_review": True},
                        cdm_events=[policy_evaluation_event],
                        user_id=current_user.id if current_user else None
                    )
                    db.add(policy_decision_db)
                    db.commit()
                    
                    policy_decision = {
                        "decision": policy_result.decision,
                        "rule_applied": policy_result.rule_applied,
                        "trace_id": policy_result.trace_id,
                        "requires_review": True
                    }
                
                # Handle ALLOW decision - log for audit
                else:
                    logger.debug(
                        f"Policy evaluation ALLOWED facility creation: trace_id={policy_result.trace_id}"
                    )
                    
                    # Log policy decision to audit trail
                    policy_decision_db = PolicyDecisionModel(
                        transaction_id=result.agreement.deal_id or result.agreement.loan_identification_number or "unknown",
                        transaction_type="facility_creation",
                        decision=policy_result.decision,
                        rule_applied=policy_result.rule_applied,
                        trace_id=policy_result.trace_id,
                        trace=policy_result.trace,
                        matched_rules=policy_result.matched_rules,
                        metadata={"document_extraction": True},
                        cdm_events=[policy_evaluation_event],
                        user_id=current_user.id if current_user else None
                    )
                    db.add(policy_decision_db)
                    db.commit()
                    
                    policy_decision = {
                        "decision": policy_result.decision,
                        "rule_applied": policy_result.rule_applied,
                        "trace_id": policy_result.trace_id
                    }
                    
            except HTTPException:
                # Re-raise HTTP exceptions (e.g., BLOCK decision)
                raise
            except Exception as e:
                # Log policy evaluation errors but don't block extraction
                logger.error(f"Policy evaluation failed: {e}", exc_info=True)
                # Continue with extraction even if policy evaluation fails
        
        message = result.message
        if result.status == ExtractionStatus.PARTIAL and not message:
            missing_fields = []
            if result.agreement:
                if not result.agreement.agreement_date:
                    missing_fields.append("agreement date")
                if not result.agreement.parties:
                    missing_fields.append("parties")
                if not result.agreement.facilities:
                    missing_fields.append("loan facilities")
                if not result.agreement.governing_law:
                    missing_fields.append("governing law")
            if missing_fields:
                message = f"Partial extraction: missing {', '.join(missing_fields)}. Please review carefully."
            else:
                message = "Some data may be incomplete. Please review the extracted information carefully."
        
        return {
            "status": result.status.value,
            "agreement": result.agreement.model_dump() if result.agreement else None,
            "message": message,
            "policy_decision": policy_decision,
            "cdm_events": [policy_evaluation_event] if policy_evaluation_event else []
        }
        
    except ValueError as e:
        logger.warning(f"Validation issue during extraction: {e}")
        raise HTTPException(
            status_code=422,
            detail={"status": "partial_data_missing", "message": str(e)}
        )
    
    except HTTPException:
        raise
    
    except Exception as e:
        logger.error(f"Unexpected error during extraction: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Extraction failed: {str(e)}"}
        )


@router.post("/upload")
async def upload_and_extract(file: UploadFile = File(...)):
    """Upload a file (PDF or TXT) and extract structured data.
    
    Args:
        file: The uploaded file.
        
    Returns:
        Extraction result with status, agreement data, extracted text, and optional message.
    """
    from app.models.cdm import ExtractionStatus
    
    filename = file.filename or ""
    extension = filename.lower().split(".")[-1] if "." in filename else ""
    
    if extension == "pdf" or (file.content_type and "pdf" in file.content_type.lower()):
        file_type = "pdf"
    elif extension == "txt" or file.content_type == "text/plain":
        file_type = "txt"
    else:
        raise HTTPException(
            status_code=400,
            detail={"status": "error", "message": f"Unsupported file type: {extension or file.content_type}. Supported types: PDF, TXT"}
        )
    
    try:
        content = await file.read()
        
        if file_type == "pdf":
            text = extract_text_from_pdf(content)
        else:
            text = content.decode("utf-8", errors="replace")
        
        if not text.strip():
            raise HTTPException(
                status_code=422,
                detail={"status": "error", "message": "The uploaded file contains no extractable text."}
            )
        
        logger.info(f"Extracted {len(text)} characters from uploaded {file_type.upper()} file")
        
        result = extract_data_smart(text=text, force_map_reduce=False)
        
        if result is None:
            raise HTTPException(
                status_code=422,
                detail={"status": "error", "message": "Extraction returned no data"}
            )
        
        if result.status == ExtractionStatus.FAILURE:
            raise HTTPException(
                status_code=422,
                detail={"status": "irrelevant_document", "message": result.message or "This document does not appear to be a credit agreement."}
            )
        
        message = result.message
        if result.status == ExtractionStatus.PARTIAL and not message:
            missing_fields = []
            if result.agreement:
                if not result.agreement.agreement_date:
                    missing_fields.append("agreement date")
                if not result.agreement.parties:
                    missing_fields.append("parties")
                if not result.agreement.facilities:
                    missing_fields.append("loan facilities")
                if not result.agreement.governing_law:
                    missing_fields.append("governing law")
            if missing_fields:
                message = f"Partial extraction: missing {', '.join(missing_fields)}. Please review carefully."
            else:
                message = "Some data may be incomplete. Please review the extracted information carefully."
        
        return {
            "status": result.status.value,
            "agreement": result.agreement.model_dump() if result.agreement else None,
            "message": message,
            "extracted_text": text
        }
        
    except ValueError as e:
        logger.warning(f"File parsing error: {e}")
        raise HTTPException(
            status_code=422,
            detail={"status": "error", "message": str(e)}
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error during file upload and extraction: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to process file: {str(e)}"}
        )


@router.post("/audio/transcribe")
async def transcribe_audio(
    file: UploadFile = File(...),
    source_lang: Optional[str] = Query(None, description="Source language code (e.g., 'en', 'es')"),
    target_lang: Optional[str] = Query(None, description="Target language code (e.g., 'en', 'es')"),
    extract_cdm: bool = Query(True, description="Whether to extract CDM data from transcription"),
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user),
):
    """Transcribe audio file and optionally extract CDM data.
    
    This endpoint:
    1. Transcribes the uploaded audio file using nvidia/canary-1b-v2
    2. Optionally extracts CDM data from the transcription using existing extraction chain
    3. Stores transcription separately for audit purposes
    
    Args:
        file: The uploaded audio file (WAV, MP3, M4A, OGG, FLAC, etc.)
        source_lang: Source language code (default: from config or 'en')
        target_lang: Target language code (default: from config or 'en')
        extract_cdm: Whether to extract CDM data from transcription (default: True)
        db: Database session
        current_user: Authenticated user (optional)
        
    Returns:
        Transcription result with transcribed text, optional CDM data, and audit info
    """
    from app.chains.audio_transcription_chain import process_audio_file
    from app.models.cdm import ExtractionStatus
    
    # Validate file type
    filename = file.filename or "audio.wav"
    extension = filename.lower().split(".")[-1] if "." in filename else ""
    supported_extensions = ["wav", "mp3", "m4a", "ogg", "flac", "webm"]
    
    if extension not in supported_extensions:
        raise HTTPException(
            status_code=400,
            detail={
                "status": "error",
                "message": f"Unsupported audio format: {extension}. Supported: {', '.join(supported_extensions)}"
            }
        )
    
    try:
        # Read audio file
        audio_bytes = await file.read()
        
        if len(audio_bytes) == 0:
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": "Uploaded file is empty"}
            )
        
        logger.info(f"Transcribing audio file: {filename} ({len(audio_bytes)} bytes)")
        
        # Transcribe audio
        try:
            transcribed_text = process_audio_file(
                audio_bytes=audio_bytes,
                filename=filename,
                source_lang=source_lang,
                target_lang=target_lang,
            )
        except ValueError as e:
            logger.error(f"Audio transcription failed: {e}")
            raise HTTPException(
                status_code=500,
                detail={"status": "error", "message": f"Audio transcription failed: {str(e)}"}
            )
        
        if not transcribed_text or not transcribed_text.strip():
            raise HTTPException(
                status_code=422,
                detail={"status": "error", "message": "Transcription returned empty text"}
            )
        
        logger.info(f"Transcription complete: {len(transcribed_text)} characters")
        
        # Prepare response
        response_data = {
            "status": "success",
            "transcription": transcribed_text,
            "transcription_length": len(transcribed_text),
            "source_filename": filename,
            "source_lang": source_lang,
            "target_lang": target_lang,
        }
        
        # Optionally extract CDM data from transcription
        if extract_cdm:
            try:
                logger.info("Extracting CDM data from transcription...")
                result = extract_data_smart(text=transcribed_text, force_map_reduce=False)
                
                if result and result.agreement:
                    response_data["agreement"] = result.agreement.model_dump()
                    response_data["extraction_status"] = result.status.value
                    response_data["extraction_message"] = result.message
                else:
                    response_data["agreement"] = None
                    response_data["extraction_status"] = "failure"
                    response_data["extraction_message"] = "CDM extraction returned no data"
                    
            except Exception as e:
                logger.warning(f"CDM extraction from transcription failed: {e}")
                response_data["agreement"] = None
                response_data["extraction_status"] = "error"
                response_data["extraction_message"] = f"CDM extraction failed: {str(e)}"
        
        # Audit log (if user is authenticated)
        if current_user:
            try:
                log_audit_action(
                    db=db,
                    action=AuditAction.CREATE,
                    target_type="audio_transcription",
                    user_id=current_user.id,
                    metadata={
                        "filename": filename,
                        "transcription_length": len(transcribed_text),
                        "extract_cdm": extract_cdm,
                        "source_lang": source_lang,
                        "target_lang": target_lang,
                    },
                )
            except Exception as e:
                logger.warning(f"Failed to log audio transcription audit: {e}")
        
        return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error during audio transcription: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to process audio file: {str(e)}"}
        )


@router.post("/image/extract")
async def extract_from_images(
    files: List[UploadFile] = File(...),
    extract_cdm: bool = Query(True, description="Whether to extract CDM data from OCR text"),
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user),
):
    """Extract text from images and optionally extract CDM data.
    
    This endpoint:
    1. Extracts text from uploaded image files using OCR (Multimodal-OCR3)
    2. Combines OCR text from all images
    3. Optionally extracts CDM data from the combined text using comprehensive extraction chain
    4. Stores OCR text separately for audit purposes
    
    Supports multiple image uploads for processing documents across multiple pages/images.
    
    Args:
        files: List of uploaded image files (PNG, JPEG, WEBP, etc.)
        extract_cdm: Whether to extract CDM data from OCR text (default: True)
        db: Database session
        current_user: Authenticated user (optional)
        
    Returns:
        Extraction result with OCR text, optional CDM data, and audit info
    """
    from app.chains.image_extraction_chain import process_multiple_image_files
    from app.chains.extraction_chain import extract_data_smart
    from app.models.cdm import ExtractionStatus
    
    # Validate file types
    supported_extensions = ["png", "jpg", "jpeg", "webp", "gif", "bmp", "tiff", "tif"]
    image_files = []
    filenames = []
    
    for file in files:
        filename = file.filename or "image.png"
        extension = filename.lower().split(".")[-1] if "." in filename else ""
        
        if extension not in supported_extensions:
            raise HTTPException(
                status_code=400,
                detail={
                    "status": "error",
                    "message": f"Unsupported image format: {extension}. Supported: {', '.join(supported_extensions)}"
                }
            )
        
        filenames.append(filename)
    
    if len(files) == 0:
        raise HTTPException(
            status_code=400,
            detail={"status": "error", "message": "No image files provided"}
        )
    
    try:
        # Read all image files
        for file in files:
            image_bytes = await file.read()
            if len(image_bytes) == 0:
                raise HTTPException(
                    status_code=400,
                    detail={"status": "error", "message": f"Uploaded file {file.filename} is empty"}
                )
            image_files.append((image_bytes, file.filename or "image.png"))
        
        logger.info(f"Processing {len(image_files)} image(s) for OCR extraction")
        
        # Extract text from all images using OCR
        try:
            ocr_texts = process_multiple_image_files(image_files)
        except ValueError as e:
            logger.error(f"Image OCR failed: {e}")
            raise HTTPException(
                status_code=500,
                detail={"status": "error", "message": f"Image OCR failed: {str(e)}"}
            )
        
        # Combine OCR text from all images
        combined_text = "\n\n--- Image Separator ---\n\n".join(
            [text if text else f"[No text extracted from {filename}]" 
             for text, filename in zip(ocr_texts, filenames)]
        )
        
        if not combined_text.strip() or combined_text.strip() == "":
            raise HTTPException(
                status_code=422,
                detail={"status": "error", "message": "OCR returned no text from any image"}
            )
        
        logger.info(f"OCR complete: {len(combined_text)} characters extracted from {len(image_files)} image(s)")
        
        # Prepare response
        response_data = {
            "status": "success",
            "ocr_text": combined_text,
            "ocr_text_length": len(combined_text),
            "source_filenames": filenames,
            "images_processed": len(image_files),
            "ocr_texts_per_image": [
                {"filename": filename, "text": text, "length": len(text)}
                for filename, text in zip(filenames, ocr_texts)
            ],
        }
        
        # Optionally extract CDM data from OCR text
        if extract_cdm:
            try:
                logger.info("Extracting CDM data from OCR text...")
                # Use comprehensive extraction prompt for better handling of various document types
                result = extract_data_smart(text=combined_text, force_map_reduce=False)
                
                if result and result.agreement:
                    response_data["agreement"] = result.agreement.model_dump()
                    response_data["extraction_status"] = result.status.value
                    response_data["extraction_message"] = result.message
                else:
                    response_data["agreement"] = None
                    response_data["extraction_status"] = "failure"
                    response_data["extraction_message"] = "CDM extraction returned no data"
                    
            except Exception as e:
                logger.warning(f"CDM extraction from OCR text failed: {e}")
                response_data["agreement"] = None
                response_data["extraction_status"] = "error"
                response_data["extraction_message"] = f"CDM extraction failed: {str(e)}"
        
        # Audit log (if user is authenticated)
        if current_user:
            try:
                log_audit_action(
                    db=db,
                    action=AuditAction.CREATE,
                    target_type="image_extraction",
                    user_id=current_user.id,
                    metadata={
                        "filenames": filenames,
                        "images_count": len(image_files),
                        "ocr_text_length": len(combined_text),
                        "extract_cdm": extract_cdm,
                    },
                )
            except Exception as e:
                logger.warning(f"Failed to log image extraction audit: {e}")
        
        return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error during image extraction: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to process image files: {str(e)}"}
        )


@router.get("/health")
async def health_check():
    """Health check endpoint that reports system status."""
    from app.db import SessionLocal, engine
    from app.core.config import settings
    from fastapi.responses import JSONResponse
    
    # Check database availability
    db_status = "unavailable"
    db_type = None
    if SessionLocal is not None and engine is not None:
        db_status = "operational"
        # Determine database type from URL
        db_url = str(engine.url) if hasattr(engine, 'url') else None
        if db_url:
            if "sqlite" in db_url.lower():
                db_type = "SQLite"
            elif "postgresql" in db_url.lower() or "postgres" in db_url.lower():
                db_type = "PostgreSQL"
            else:
                db_type = "Unknown"
    
    status = {
        "status": "healthy",
        "service": "CreditNexus API",
        "services": {
            "api": "operational",
            "database": {
                "status": db_status,
                "type": db_type,
                "enabled": settings.DATABASE_ENABLED
            },
            "llm": "operational",  # TODO: Add actual LLM health check
            "policy_engine": "operational" if settings.POLICY_ENABLED else "disabled",
        }
    }
    
    # Mark as degraded if database is unavailable but enabled
    if settings.DATABASE_ENABLED and db_status == "unavailable":
        status["status"] = "degraded"
        status["warnings"] = ["Database is enabled but not available"]
    
    status_code = 200 if status["status"] == "healthy" else 503
    return JSONResponse(content=status, status_code=status_code)


class ApproveRequest(BaseModel):
    """Request model for approving an extraction."""
    agreement_data: dict = Field(..., description="The extracted agreement data to approve")
    original_text: Optional[str] = Field(None, description="The original document text")
    source_filename: Optional[str] = Field(None, description="The source file name")
    reviewed_by: Optional[str] = Field(None, description="Who reviewed the extraction")


class RejectRequest(BaseModel):
    """Request model for rejecting an extraction."""
    agreement_data: dict = Field(..., description="The extracted agreement data being rejected")
    rejection_reason: str = Field(..., description="Reason for rejecting the extraction")
    original_text: Optional[str] = Field(None, description="The original document text")
    source_filename: Optional[str] = Field(None, description="The source file name")
    reviewed_by: Optional[str] = Field(None, description="Who reviewed the extraction")


@router.post("/approve")
async def approve_extraction(request: ApproveRequest, db: Session = Depends(get_db)):
    """Approve and store an extraction in the staging database.
    
    Args:
        request: ApproveRequest containing the agreement data and metadata.
        db: Database session.
        
    Returns:
        The created staged extraction record.
    """
    try:
        staged = StagedExtraction(
            status=ExtractionStatus.APPROVED.value,
            agreement_data=request.agreement_data,
            original_text=request.original_text,
            source_filename=request.source_filename,
            reviewed_by=request.reviewed_by,
        )
        db.add(staged)
        db.commit()
        db.refresh(staged)
        
        logger.info(f"Approved extraction saved with ID: {staged.id}")
        
        return {
            "status": "success",
            "message": "Extraction approved and saved",
            "extraction": staged.to_dict()
        }
    except Exception as e:
        db.rollback()
        logger.error(f"Error saving approved extraction: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to save extraction: {str(e)}"}
        )


@router.post("/reject")
async def reject_extraction(request: RejectRequest, db: Session = Depends(get_db)):
    """Reject and store an extraction in the staging database with a reason.
    
    Args:
        request: RejectRequest containing the agreement data, reason, and metadata.
        db: Database session.
        
    Returns:
        The created staged extraction record.
    """
    try:
        staged = StagedExtraction(
            status=ExtractionStatus.REJECTED.value,
            agreement_data=request.agreement_data,
            original_text=request.original_text,
            source_filename=request.source_filename,
            rejection_reason=request.rejection_reason,
            reviewed_by=request.reviewed_by,
        )
        db.add(staged)
        db.commit()
        db.refresh(staged)
        
        logger.info(f"Rejected extraction saved with ID: {staged.id}")
        
        return {
            "status": "success",
            "message": "Extraction rejected and saved",
            "extraction": staged.to_dict()
        }
    except Exception as e:
        db.rollback()
        logger.error(f"Error saving rejected extraction: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to save rejection: {str(e)}"}
        )


@router.get("/extractions")
async def list_extractions(
    status: Optional[str] = Query(None, description="Filter by status (pending, approved, rejected)"),
    limit: int = Query(50, ge=1, le=100, description="Maximum number of results"),
    offset: int = Query(0, ge=0, description="Offset for pagination"),
    db: Session = Depends(get_db)
):
    """List staged extractions with optional filtering.
    
    Args:
        status: Optional status filter.
        limit: Maximum number of results (default 50, max 100).
        offset: Pagination offset.
        db: Database session.
        
    Returns:
        List of staged extractions.
    """
    try:
        query = db.query(StagedExtraction)
        
        if status:
            if status not in [s.value for s in ExtractionStatus]:
                raise HTTPException(
                    status_code=400,
                    detail={"status": "error", "message": f"Invalid status: {status}. Must be one of: pending, approved, rejected"}
                )
            query = query.filter(StagedExtraction.status == status)
        
        total = query.count()
        
        extractions = query.order_by(StagedExtraction.created_at.desc()).offset(offset).limit(limit).all()
        
        return {
            "status": "success",
            "total": total,
            "limit": limit,
            "offset": offset,
            "extractions": [e.to_dict() for e in extractions]
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error listing extractions: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to list extractions: {str(e)}"}
        )


class CreateDocumentRequest(BaseModel):
    """Request model for creating a new document."""
    title: str = Field(..., description="Document title")
    agreement_data: dict = Field(..., description="The extracted agreement data")
    original_text: Optional[str] = Field(None, description="The original document text")
    source_filename: Optional[str] = Field(None, description="The source file name")
    extraction_method: str = Field("simple", description="The extraction method used")
    # LMA Template Generation fields
    is_generated: Optional[bool] = Field(False, description="Whether this document was generated from a template")
    template_id: Optional[int] = Field(None, description="LMA template ID if generated from template")
    source_cdm_data: Optional[dict] = Field(None, description="Source CDM data used for generation")


class CreateVersionRequest(BaseModel):
    """Request model for creating a new document version."""
    agreement_data: dict = Field(..., description="The updated extracted agreement data")
    original_text: Optional[str] = Field(None, description="The original document text")
    source_filename: Optional[str] = Field(None, description="The source file name")
    extraction_method: str = Field("simple", description="The extraction method used")


class TradeExecutionRequest(BaseModel):
    """Request model for trade execution with policy evaluation."""
    trade_id: str = Field(..., description="Unique trade identifier")
    borrower: str = Field(..., description="Borrower name or identifier")
    amount: float = Field(..., gt=0, description="Trade amount (must be positive)")
    rate: float = Field(..., ge=0, description="Interest rate (percentage or basis points)")
    credit_agreement_id: Optional[int] = Field(None, description="Optional credit agreement ID for context")


def extract_document_metadata(agreement_data: dict) -> dict:
    """Extract document-level metadata from agreement data."""
    metadata = {}
    
    if "agreement_date" in agreement_data and agreement_data["agreement_date"]:
        try:
            if isinstance(agreement_data["agreement_date"], str):
                metadata["agreement_date"] = datetime.fromisoformat(agreement_data["agreement_date"].replace("Z", "+00:00")).date()
            else:
                metadata["agreement_date"] = agreement_data["agreement_date"]
        except (ValueError, TypeError):
            pass
    
    if "governing_law" in agreement_data:
        metadata["governing_law"] = agreement_data["governing_law"]
    
    parties = agreement_data.get("parties", [])
    for party in parties:
        role = party.get("role", "")
        if isinstance(role, str) and "borrower" in role.lower():
            metadata["borrower_name"] = party.get("name") or party.get("legal_name")
            metadata["borrower_lei"] = party.get("lei")
            break
    
    facilities = agreement_data.get("facilities", [])
    if facilities:
        total = Decimal("0")
        currency = None
        for facility in facilities:
            if not isinstance(facility, dict):
                continue
            commitment = facility.get("commitment_amount") or facility.get("commitment")
            if commitment and isinstance(commitment, dict):
                amount = commitment.get("amount")
                if amount:
                    total += Decimal(str(amount))
                if not currency and commitment.get("currency"):
                    currency = commitment["currency"]
        if total > 0:
            metadata["total_commitment"] = total
            metadata["currency"] = currency
    
    sustainability = agreement_data.get("sustainability_provisions")
    if sustainability and isinstance(sustainability, dict):
        metadata["sustainability_linked"] = sustainability.get("is_sustainability_linked", False)
        metadata["esg_metadata"] = sustainability
    elif agreement_data.get("sustainability_linked"):
        metadata["sustainability_linked"] = agreement_data.get("sustainability_linked", False)
    
    # Extract transaction identifiers for policy decision lookup
    if agreement_data.get("deal_id"):
        metadata["deal_id"] = agreement_data.get("deal_id")
    if agreement_data.get("loan_identification_number"):
        metadata["loan_identification_number"] = agreement_data.get("loan_identification_number")
    
    return metadata


@router.post("/documents")
async def create_document(
    doc_request: CreateDocumentRequest,
    request: Request,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """Create a new document with its first version.
    
    Args:
        doc_request: CreateDocumentRequest containing the document data.
        request: The HTTP request.
        db: Database session.
        current_user: The authenticated user.
        
    Returns:
        The created document with its first version.
    """
    try:
        metadata = extract_document_metadata(doc_request.agreement_data)
        
        doc = Document(
            title=doc_request.title,
            borrower_name=metadata.get("borrower_name"),
            borrower_lei=metadata.get("borrower_lei"),
            governing_law=metadata.get("governing_law"),
            total_commitment=metadata.get("total_commitment"),
            currency=metadata.get("currency"),
            agreement_date=metadata.get("agreement_date"),
            sustainability_linked=metadata.get("sustainability_linked", False),
            esg_metadata=metadata.get("esg_metadata"),
            uploaded_by=current_user.id,
            # LMA Template Generation fields
            is_generated=doc_request.is_generated or False,
            template_id=doc_request.template_id,
            source_cdm_data=doc_request.source_cdm_data,
        )
        db.add(doc)
        db.flush()
        
        version = DocumentVersion(
            document_id=doc.id,
            version_number=1,
            extracted_data=doc_request.agreement_data,
            original_text=doc_request.original_text,
            source_filename=doc_request.source_filename,
            extraction_method=doc_request.extraction_method,
            created_by=current_user.id,
        )
        db.add(version)
        db.flush()
        
        doc.current_version_id = version.id
        
        # Check for policy decisions that might affect workflow priority
        # Look for recent policy decisions for this transaction (deal_id or loan_identification_number)
        priority = "normal"
        # Set initial state based on whether document is generated
        if doc_request.is_generated:
            initial_state = WorkflowState.GENERATED.value
        else:
            initial_state = WorkflowState.DRAFT.value
        
        if metadata.get("deal_id") or metadata.get("loan_identification_number"):
            transaction_id = metadata.get("deal_id") or metadata.get("loan_identification_number")
            
            # Query for recent policy decision for this transaction
            recent_policy_decision = db.query(PolicyDecisionModel).filter(
                PolicyDecisionModel.transaction_id == transaction_id,
                PolicyDecisionModel.transaction_type == "facility_creation"
            ).order_by(PolicyDecisionModel.created_at.desc()).first()
            
            if recent_policy_decision:
                if recent_policy_decision.decision == "FLAG":
                    # FLAG decision: set high priority and mark for review
                    priority = "high"
                    logger.info(
                        f"Workflow for document {doc.id} set to high priority due to FLAG policy decision: "
                        f"{recent_policy_decision.rule_applied}"
                    )
                elif recent_policy_decision.decision == "BLOCK":
                    # BLOCK decision: This should have been caught earlier, but log it
                    logger.warning(
                        f"Document {doc.id} created despite BLOCK policy decision: "
                        f"{recent_policy_decision.rule_applied}"
                    )
                    priority = "high"  # Still set high priority for visibility
        
        workflow = Workflow(
            document_id=doc.id,
            state=initial_state,
            priority=priority,
        )
        db.add(workflow)
        
        log_audit_action(
            db=db,
            action=AuditAction.CREATE,
            target_type="document",
            target_id=doc.id,
            user_id=current_user.id,
            metadata={"title": doc_request.title, "borrower_name": metadata.get("borrower_name")},
            request=request
        )
        
        db.commit()
        db.refresh(doc)
        db.refresh(version)
        
        logger.info(f"Created document {doc.id} with version {version.id} by user {current_user.id}")
        
        return {
            "status": "success",
            "message": "Document created successfully",
            "document": {
                **doc.to_dict(),
                "versions": [version.to_dict()],
                "workflow": workflow.to_dict() if workflow else None,
            }
        }
    except Exception as e:
        db.rollback()
        logger.error(f"Error creating document: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to create document: {str(e)}"}
        )


@router.get("/documents")
async def list_documents(
    search: Optional[str] = Query(None, description="Search term for title or borrower name"),
    limit: int = Query(50, ge=1, le=100, description="Maximum number of results"),
    offset: int = Query(0, ge=0, description="Offset for pagination"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """List documents with optional filtering.
    
    Args:
        search: Optional search term.
        limit: Maximum number of results (default 50, max 100).
        offset: Pagination offset.
        db: Database session.
        current_user: The current user (optional).
        
    Returns:
        List of documents with summary information.
    """
    try:
        query = db.query(Document).options(
            joinedload(Document.workflow),
            joinedload(Document.uploaded_by_user)
        )
        
        if search:
            search_term = f"%{search}%"
            query = query.filter(
                (Document.title.ilike(search_term)) |
                (Document.borrower_name.ilike(search_term))
            )
        
        total = query.count()
        
        documents = query.order_by(Document.updated_at.desc()).offset(offset).limit(limit).all()
        
        result = []
        for doc in documents:
            doc_dict = doc.to_dict()
            doc_dict["workflow_state"] = doc.workflow.state if doc.workflow else None
            doc_dict["uploaded_by_name"] = doc.uploaded_by_user.display_name if doc.uploaded_by_user else None
            result.append(doc_dict)
        
        return {
            "status": "success",
            "total": total,
            "limit": limit,
            "offset": offset,
            "documents": result
        }
    except Exception as e:
        logger.error(f"Error listing documents: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to list documents: {str(e)}"}
        )


@router.get("/documents/{document_id}")
async def get_document(
    document_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Get a document with all its versions.
    
    Args:
        document_id: The document ID.
        db: Database session.
        current_user: The current user (optional).
        
    Returns:
        The document with all versions.
    """
    try:
        doc = db.query(Document).options(
            joinedload(Document.versions),
            joinedload(Document.workflow),
            joinedload(Document.uploaded_by_user)
        ).filter(Document.id == document_id).first()
        
        if not doc:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": "Document not found"}
            )
        
        doc_dict = doc.to_dict()
        doc_dict["versions"] = [v.to_dict() for v in doc.versions]
        doc_dict["workflow"] = doc.workflow.to_dict() if doc.workflow else None
        doc_dict["uploaded_by_name"] = doc.uploaded_by_user.display_name if doc.uploaded_by_user else None
        
        return {
            "status": "success",
            "document": doc_dict
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting document {document_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to get document: {str(e)}"}
        )


class DocumentRetrieveRequest(BaseModel):
    """Request model for document retrieval."""
    query: str = Field(..., description="Query text or CDM data (JSON string) to search for similar documents")
    top_k: int = Field(5, ge=1, le=20, description="Number of similar documents to retrieve (default: 5, max: 20)")
    filter_metadata: Optional[Dict[str, Any]] = Field(None, description="Optional metadata filters (e.g., {'borrower_name': 'ACME Corp'})")
    extract_cdm: bool = Field(True, description="Whether to extract CDM data from retrieved documents")


@router.post("/documents/retrieve")
async def retrieve_similar_documents(
    request: DocumentRetrieveRequest,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user),
):
    """Retrieve similar documents based on query text or CDM data.
    
    This endpoint:
    1. Searches for similar documents using ChromaDB vector similarity
    2. Fetches full document data from the database
    3. Returns similar documents with their CDM data
    
    Args:
        request: DocumentRetrieveRequest with query, top_k, and optional filters
        db: Database session
        current_user: Authenticated user (optional)
        
    Returns:
        List of similar documents with CDM data, similarity scores, and metadata
    """
    from app.chains.document_retrieval_chain import retrieve_similar_documents as retrieve_docs
    from app.models.cdm import CreditAgreement
    
    try:
        # Parse query - check if it's JSON (CDM data) or plain text
        query = request.query.strip()
        query_data = None
        
        # Try to parse as JSON (CDM data)
        try:
            query_data = json.loads(query)
            if isinstance(query_data, dict):
                query = query_data  # Use dict for CDM-based search
        except (json.JSONDecodeError, ValueError):
            # Not JSON, use as plain text query
            pass
        
        logger.info(f"Retrieving similar documents for query: {query[:100] if isinstance(query, str) else 'CDM data'}...")
        
        # Retrieve similar documents from ChromaDB
        try:
            similar_docs = retrieve_docs(
                query=query,
                top_k=request.top_k,
                filter_metadata=request.filter_metadata,
            )
        except ImportError as e:
            logger.error(f"ChromaDB not available: {e}")
            raise HTTPException(
                status_code=503,
                detail={
                    "status": "error",
                    "message": "Document retrieval service is not available. ChromaDB is not installed."
                }
            )
        except Exception as e:
            logger.error(f"Document retrieval failed: {e}")
            raise HTTPException(
                status_code=500,
                detail={
                    "status": "error",
                    "message": f"Document retrieval failed: {str(e)}"
                }
            )
        
        if not similar_docs:
            return {
                "status": "success",
                "query": query if isinstance(query, str) else "CDM data",
                "results_count": 0,
                "documents": []
            }
        
        # Fetch full document data from database
        results = []
        for doc_result in similar_docs:
            document_id = doc_result["document_id"]
            
            try:
                # Fetch document from database
                doc = db.query(Document).options(
                    joinedload(Document.versions),
                    joinedload(Document.workflow),
                    joinedload(Document.uploaded_by_user)
                ).filter(Document.id == document_id).first()
                
                if not doc:
                    logger.warning(f"Document {document_id} not found in database (may have been deleted)")
                    continue
                
                # Get CDM data from document
                cdm_data = None
                if request.extract_cdm:
                    # Try to get CDM data from source_cdm_data or latest version
                    if doc.source_cdm_data:
                        cdm_data = doc.source_cdm_data
                    elif doc.current_version_id:
                        version = db.query(DocumentVersion).filter(
                            DocumentVersion.id == doc.current_version_id
                        ).first()
                        if version and version.extracted_data:
                            cdm_data = version.extracted_data
                
                # Build result
                result_item = {
                    "document_id": document_id,
                    "similarity_score": doc_result["similarity_score"],
                    "distance": doc_result["distance"],
                    "document": doc.to_dict(),
                    "cdm_data": cdm_data,
                }
                
                # Add workflow info if available
                if doc.workflow:
                    result_item["workflow"] = doc.workflow.to_dict()
                
                # Add version info
                if doc.versions:
                    result_item["latest_version"] = doc.versions[0].to_dict() if doc.versions else None
                
                results.append(result_item)
                
            except Exception as e:
                logger.error(f"Error fetching document {document_id}: {e}")
                # Continue with other documents even if one fails
                continue
        
        # Audit log (if user is authenticated)
        if current_user:
            try:
                log_audit_action(
                    db=db,
                    action=AuditAction.CREATE,
                    target_type="document_retrieval",
                    user_id=current_user.id,
                    metadata={
                        "query": query[:200] if isinstance(query, str) else "CDM data",
                        "results_count": len(results),
                        "top_k": request.top_k,
                    },
                )
            except Exception as e:
                logger.warning(f"Failed to log document retrieval audit: {e}")
        
        return {
            "status": "success",
            "query": query if isinstance(query, str) else "CDM data",
            "results_count": len(results),
            "documents": results
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error during document retrieval: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to retrieve documents: {str(e)}"}
        )


class MultimodalFusionRequest(BaseModel):
    """Request model for multimodal CDM fusion."""
    audio_cdm: Optional[Dict[str, Any]] = Field(None, description="Optional CDM data from audio transcription")
    image_cdm: Optional[Dict[str, Any]] = Field(None, description="Optional CDM data from image OCR")
    document_cdm: Optional[Dict[str, Any]] = Field(None, description="Optional CDM data from document retrieval")
    text_cdm: Optional[Dict[str, Any]] = Field(None, description="Optional CDM data from text extraction")
    audio_text: Optional[str] = Field(None, description="Optional raw transcription text from audio")
    image_text: Optional[str] = Field(None, description="Optional raw OCR text from images")
    document_text: Optional[str] = Field(None, description="Optional raw text from retrieved document")
    text_input: Optional[str] = Field(None, description="Required text input (if no text_cdm provided)")
    use_llm_fusion: bool = Field(True, description="Whether to use LLM for complex merging (default: True)")


@router.post("/multimodal/fuse")
async def fuse_multimodal_cdm(
    request: MultimodalFusionRequest,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user),
):
    """Fuse CDM data from multiple sources into a unified CDM structure.
    
    This endpoint:
    1. Accepts CDM data from multiple sources (audio, image, document, text)
    2. Prepends optional inputs (audio, image) to required inputs (document, text)
    3. Tracks source for each field
    4. Detects conflicts between sources
    5. Uses deterministic fallbacks for simple cases
    6. Uses LLM for complex merging when conflicts exist
    
    Args:
        request: MultimodalFusionRequest with CDM data and/or text from various sources
        db: Database session
        current_user: Authenticated user (optional)
        
    Returns:
        Fused CDM data with source tracking, conflicts, and fusion method
    """
    from app.chains.multimodal_fusion_chain import fuse_multimodal_inputs
    
    try:
        # Validate that at least one source is provided
        has_cdm = any([
            request.audio_cdm,
            request.image_cdm,
            request.document_cdm,
            request.text_cdm,
        ])
        has_text = any([
            request.audio_text,
            request.image_text,
            request.document_text,
            request.text_input,
        ])
        
        if not has_cdm and not has_text:
            raise HTTPException(
                status_code=400,
                detail={
                    "status": "error",
                    "message": "At least one CDM data source or text input must be provided"
                }
            )
        
        logger.info(
            f"Fusing multimodal inputs: "
            f"audio_cdm={request.audio_cdm is not None}, "
            f"image_cdm={request.image_cdm is not None}, "
            f"document_cdm={request.document_cdm is not None}, "
            f"text_cdm={request.text_cdm is not None}, "
            f"text_input={request.text_input is not None}"
        )
        
        # Perform fusion
        try:
            fusion_result = fuse_multimodal_inputs(
                audio_cdm=request.audio_cdm,
                image_cdm=request.image_cdm,
                document_cdm=request.document_cdm,
                text_cdm=request.text_cdm,
                audio_text=request.audio_text,
                image_text=request.image_text,
                document_text=request.document_text,
                text_input=request.text_input,
                use_llm_fusion=request.use_llm_fusion,
            )
        except ValueError as e:
            logger.error(f"Fusion failed: {e}")
            raise HTTPException(
                status_code=422,
                detail={
                    "status": "error",
                    "message": f"Fusion failed: {str(e)}"
                }
            )
        except Exception as e:
            logger.error(f"Unexpected error during fusion: {e}", exc_info=True)
            raise HTTPException(
                status_code=500,
                detail={
                    "status": "error",
                    "message": f"Fusion failed with unexpected error: {str(e)}"
                }
            )
        
        # Prepare response
        response_data = {
            "status": "success",
            "agreement": fusion_result.agreement.model_dump(),
            "source_tracking": {
                field: src.to_dict()
                for field, src in fusion_result.source_tracking.items()
            },
            "conflicts": [c.to_dict() for c in fusion_result.conflicts],
            "fusion_method": fusion_result.fusion_method,
            "conflicts_count": len(fusion_result.conflicts),
        }
        
        # Audit log (if user is authenticated)
        if current_user:
            try:
                log_audit_action(
                    db=db,
                    action=AuditAction.CREATE,
                    target_type="multimodal_fusion",
                    user_id=current_user.id,
                    metadata={
                        "sources_count": sum([
                            1 if request.audio_cdm else 0,
                            1 if request.image_cdm else 0,
                            1 if request.document_cdm else 0,
                            1 if request.text_cdm else 0,
                        ]),
                        "fusion_method": fusion_result.fusion_method,
                        "conflicts_count": len(fusion_result.conflicts),
                        "use_llm_fusion": request.use_llm_fusion,
                    },
                )
            except Exception as e:
                logger.warning(f"Failed to log multimodal fusion audit: {e}")
        
        return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error during multimodal fusion: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to fuse multimodal inputs: {str(e)}"}
        )


class ChatbotChatRequest(BaseModel):
    """Request model for chatbot chat."""
    message: str = Field(..., description="User message")
    conversation_history: Optional[List[Dict[str, str]]] = Field(
        None,
        description="Previous conversation messages [{\"role\": \"user\"|\"assistant\", \"content\": \"...\"}]"
    )
    cdm_context: Optional[Dict[str, Any]] = Field(
        None,
        description="Current CDM data context"
    )
    use_kb: bool = Field(True, description="Whether to use knowledge base retrieval (default: True)")


@router.post("/chatbot/chat")
async def chatbot_chat(
    request: ChatbotChatRequest,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user),
):
    """Chat with the decision support chatbot.
    
    This endpoint provides an AI chatbot interface for:
    - Answering questions about LMA templates and CDM schema
    - Providing guidance on template selection
    - Helping with field filling
    - General document generation assistance
    
    Uses RAG (Retrieval Augmented Generation) with ChromaDB knowledge base.
    
    Args:
        request: ChatbotChatRequest with message, conversation history, and CDM context
        db: Database session
        current_user: Authenticated user (optional)
        
    Returns:
        Chatbot response with answer, sources, and metadata
    """
    from app.chains.decision_support_chain import DecisionSupportChatbot
    
    try:
        # Initialize chatbot (could be cached/singleton in production)
        chatbot = DecisionSupportChatbot()
        
        logger.info(f"Chatbot chat request: message length={len(request.message)}, has_cdm_context={request.cdm_context is not None}")
        
        # Call chatbot
        try:
            result = chatbot.chat(
                message=request.message,
                conversation_history=request.conversation_history,
                cdm_context=request.cdm_context,
                use_kb=request.use_kb,
            )
        except ImportError as e:
            logger.error(f"ChromaDB not available: {e}")
            raise HTTPException(
                status_code=503,
                detail={
                    "status": "error",
                    "message": "Chatbot service is not available. ChromaDB is not installed."
                }
            )
        except Exception as e:
            logger.error(f"Chatbot chat failed: {e}", exc_info=True)
            raise HTTPException(
                status_code=500,
                detail={
                    "status": "error",
                    "message": f"Chatbot failed: {str(e)}"
                }
            )
        
        # Prepare response
        response_data = {
            "status": "success",
            "response": result.get("response", ""),
            "sources": result.get("sources", []),
            "context_used": result.get("context_used", False),
        }
        
        if "error" in result:
            response_data["error"] = result["error"]
        
        # Audit log (if user is authenticated)
        if current_user:
            try:
                log_audit_action(
                    db=db,
                    action=AuditAction.CREATE,
                    target_type="chatbot_chat",
                    user_id=current_user.id,
                    metadata={
                        "message_length": len(request.message),
                        "has_cdm_context": request.cdm_context is not None,
                        "has_conversation_history": request.conversation_history is not None,
                        "use_kb": request.use_kb,
                        "context_used": result.get("context_used", False),
                    },
                )
            except Exception as e:
                logger.warning(f"Failed to log chatbot chat audit: {e}")
        
        return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error during chatbot chat: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to process chat message: {str(e)}"}
        )


class ChatbotSuggestTemplatesRequest(BaseModel):
    """Request model for template suggestions."""
    cdm_data: Dict[str, Any] = Field(..., description="CDM data to analyze for template suggestions")
    category_filter: Optional[str] = Field(None, description="Optional category filter for templates")


@router.post("/chatbot/suggest-templates")
async def chatbot_suggest_templates(
    request: ChatbotSuggestTemplatesRequest,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user),
):
    """Get template suggestions based on CDM data.
    
    This endpoint uses AI to analyze CDM data and suggest appropriate LMA templates.
    It considers:
    - Agreement type and structure
    - Governing law requirements
    - Sustainability-linked loan indicators
    - Complexity and specific clauses needed
    
    Args:
        request: ChatbotSuggestTemplatesRequest with CDM data and optional category filter
        db: Database session
        current_user: Authenticated user (optional)
        
    Returns:
        Template suggestions with reasoning and CDM analysis
    """
    from app.chains.decision_support_chain import DecisionSupportChatbot
    from app.templates.registry import TemplateRegistry
    
    try:
        # Get available templates from database
        available_templates = []
        try:
            templates = TemplateRegistry.list_templates(
                db=db,
                category=request.category_filter
            )
            available_templates = [t.to_dict() for t in templates]
        except Exception as e:
            logger.warning(f"Failed to load templates from database: {e}")
            # Continue without template list - chatbot can still provide suggestions
        
        # Initialize chatbot
        chatbot = DecisionSupportChatbot()
        
        logger.info(f"Template suggestion request: has_cdm_data={bool(request.cdm_data)}, templates_count={len(available_templates)}")
        
        # Get suggestions
        try:
            result = chatbot.suggest_template(
                cdm_data=request.cdm_data,
                available_templates=available_templates if available_templates else None,
            )
        except ImportError as e:
            logger.error(f"ChromaDB not available: {e}")
            raise HTTPException(
                status_code=503,
                detail={
                    "status": "error",
                    "message": "Template suggestion service is not available. ChromaDB is not installed."
                }
            )
        except Exception as e:
            logger.error(f"Template suggestion failed: {e}", exc_info=True)
            raise HTTPException(
                status_code=500,
                detail={
                    "status": "error",
                    "message": f"Template suggestion failed: {str(e)}"
                }
            )
        
        # Prepare response
        response_data = {
            "status": "success",
            "suggestions": result.get("suggestions", []),
            "reasoning": result.get("reasoning", ""),
            "cdm_analysis": result.get("cdm_analysis", {}),
        }
        
        if "error" in result:
            response_data["error"] = result["error"]
        
        # Audit log (if user is authenticated)
        if current_user:
            try:
                log_audit_action(
                    db=db,
                    action=AuditAction.CREATE,
                    target_type="chatbot_template_suggestion",
                    user_id=current_user.id,
                    metadata={
                        "suggestions_count": len(result.get("suggestions", [])),
                        "has_parties": result.get("cdm_analysis", {}).get("has_parties", False),
                        "has_facilities": result.get("cdm_analysis", {}).get("has_facilities", False),
                        "is_sustainability_linked": result.get("cdm_analysis", {}).get("is_sustainability_linked", False),
                        "category_filter": request.category_filter,
                    },
                )
            except Exception as e:
                logger.warning(f"Failed to log template suggestion audit: {e}")
        
        return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error during template suggestion: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to suggest templates: {str(e)}"}
        )


class ChatbotFillFieldsRequest(BaseModel):
    """Request model for filling missing CDM fields."""
    cdm_data: Dict[str, Any] = Field(..., description="Current CDM data (may be incomplete)")
    required_fields: List[str] = Field(..., description="List of required field paths (e.g., [\"parties\", \"facilities[0].facility_name\"])")
    conversation_context: Optional[str] = Field(None, description="Optional conversation context about what user is trying to do")


@router.post("/chatbot/fill-fields")
async def chatbot_fill_fields(
    request: ChatbotFillFieldsRequest,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user),
):
    """Help fill missing CDM fields interactively.
    
    This endpoint uses AI to:
    - Identify missing required fields in CDM data
    - Provide guidance on what each field represents
    - Ask clarifying questions
    - Suggest values based on existing data
    - Provide example values for reference
    
    Args:
        request: ChatbotFillFieldsRequest with CDM data, required fields, and optional context
        db: Database session
        current_user: Authenticated user (optional)
        
    Returns:
        Field filling assistance with suggestions, questions, and guidance
    """
    from app.chains.decision_support_chain import DecisionSupportChatbot
    
    try:
        # Validate required fields
        if not request.required_fields:
            raise HTTPException(
                status_code=400,
                detail={
                    "status": "error",
                    "message": "required_fields cannot be empty"
                }
            )
        
        # Initialize chatbot
        chatbot = DecisionSupportChatbot()
        
        logger.info(
            f"Field filling request: required_fields_count={len(request.required_fields)}, "
            f"has_cdm_data={bool(request.cdm_data)}, has_context={bool(request.conversation_context)}"
        )
        
        # Get field filling assistance
        try:
            result = chatbot.fill_missing_fields(
                cdm_data=request.cdm_data,
                required_fields=request.required_fields,
                conversation_context=request.conversation_context,
            )
        except ImportError as e:
            logger.error(f"ChromaDB not available: {e}")
            raise HTTPException(
                status_code=503,
                detail={
                    "status": "error",
                    "message": "Field filling service is not available. ChromaDB is not installed."
                }
            )
        except Exception as e:
            logger.error(f"Field filling failed: {e}", exc_info=True)
            raise HTTPException(
                status_code=500,
                detail={
                    "status": "error",
                    "message": f"Field filling failed: {str(e)}"
                }
            )
        
        # Prepare response
        response_data = {
            "status": "success",
            "all_fields_present": result.get("all_fields_present", False),
            "missing_fields": result.get("missing_fields", []),
            "suggestions": result.get("suggestions", {}),
            "guidance": result.get("guidance", ""),
            "questions": result.get("questions", []),
        }
        
        if "error" in result:
            response_data["error"] = result["error"]
        
        # If all fields are present, include the filled data
        if result.get("all_fields_present"):
            response_data["filled_data"] = result.get("filled_data", request.cdm_data)
        
        # Audit log (if user is authenticated)
        if current_user:
            try:
                log_audit_action(
                    db=db,
                    action=AuditAction.CREATE,
                    target_type="chatbot_fill_fields",
                    user_id=current_user.id,
                    metadata={
                        "required_fields_count": len(request.required_fields),
                        "missing_fields_count": len(result.get("missing_fields", [])),
                        "all_fields_present": result.get("all_fields_present", False),
                        "has_conversation_context": bool(request.conversation_context),
                    },
                )
            except Exception as e:
                logger.warning(f"Failed to log field filling audit: {e}")
        
        return response_data
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error during field filling: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to fill fields: {str(e)}"}
        )


@router.get("/documents/{document_id}/versions")
async def list_document_versions(
    document_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """List all versions of a document.
    
    Args:
        document_id: The document ID.
        db: Database session.
        current_user: The current user (optional).
        
    Returns:
        List of document versions.
    """
    try:
        doc = db.query(Document).filter(Document.id == document_id).first()
        
        if not doc:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": "Document not found"}
            )
        
        versions = db.query(DocumentVersion).filter(
            DocumentVersion.document_id == document_id
        ).order_by(DocumentVersion.version_number.desc()).all()
        
        return {
            "status": "success",
            "document_id": document_id,
            "current_version_id": doc.current_version_id,
            "versions": [v.to_dict() for v in versions]
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error listing versions for document {document_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to list versions: {str(e)}"}
        )


@router.get("/documents/{document_id}/versions/{version_id}")
async def get_document_version(
    document_id: int,
    version_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Get a specific version of a document.
    
    Args:
        document_id: The document ID.
        version_id: The version ID.
        db: Database session.
        current_user: The current user (optional).
        
    Returns:
        The document version with full extracted data.
    """
    try:
        version = db.query(DocumentVersion).filter(
            DocumentVersion.id == version_id,
            DocumentVersion.document_id == document_id
        ).first()
        
        if not version:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": "Version not found"}
            )
        
        return {
            "status": "success",
            "version": version.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting version {version_id} for document {document_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to get version: {str(e)}"}
        )


@router.post("/documents/{document_id}/versions")
async def create_document_version(
    document_id: int,
    version_request: CreateVersionRequest,
    request: Request,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """Create a new version of a document.
    
    Args:
        document_id: The document ID.
        version_request: CreateVersionRequest containing the new version data.
        request: The HTTP request.
        db: Database session.
        current_user: The authenticated user.
        
    Returns:
        The created version.
    """
    try:
        doc = db.query(Document).filter(Document.id == document_id).first()
        
        if not doc:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": "Document not found"}
            )
        
        latest_version = db.query(DocumentVersion).filter(
            DocumentVersion.document_id == document_id
        ).order_by(DocumentVersion.version_number.desc()).first()
        
        new_version_number = (latest_version.version_number + 1) if latest_version else 1
        
        version = DocumentVersion(
            document_id=document_id,
            version_number=new_version_number,
            extracted_data=version_request.agreement_data,
            original_text=version_request.original_text,
            source_filename=version_request.source_filename,
            extraction_method=version_request.extraction_method,
            created_by=current_user.id,
        )
        db.add(version)
        db.flush()
        
        metadata = extract_document_metadata(version_request.agreement_data)
        doc.borrower_name = metadata.get("borrower_name", doc.borrower_name)
        doc.borrower_lei = metadata.get("borrower_lei", doc.borrower_lei)
        doc.governing_law = metadata.get("governing_law", doc.governing_law)
        doc.total_commitment = metadata.get("total_commitment", doc.total_commitment)
        doc.currency = metadata.get("currency", doc.currency)
        doc.agreement_date = metadata.get("agreement_date", doc.agreement_date)
        doc.sustainability_linked = metadata.get("sustainability_linked", doc.sustainability_linked)
        if metadata.get("esg_metadata"):
            doc.esg_metadata = metadata["esg_metadata"]
        doc.current_version_id = version.id
        
        log_audit_action(
            db=db,
            action=AuditAction.UPDATE,
            target_type="document",
            target_id=document_id,
            user_id=current_user.id,
            metadata={"version_number": new_version_number, "version_id": version.id},
            request=request
        )
        
        db.commit()
        db.refresh(version)
        
        logger.info(f"Created version {version.id} (v{new_version_number}) for document {document_id} by user {current_user.id}")
        
        return {
            "status": "success",
            "message": f"Version {new_version_number} created successfully",
            "version": version.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Error creating version for document {document_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to create version: {str(e)}"}
        )


@router.delete("/documents/{document_id}")
async def delete_document(
    document_id: int,
    request: Request,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """Delete a document and all its versions.
    
    Args:
        document_id: The document ID.
        request: The HTTP request.
        db: Database session.
        current_user: The authenticated user.
        
    Returns:
        Success message.
    """
    try:
        doc = db.query(Document).filter(Document.id == document_id).first()
        
        if not doc:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": "Document not found"}
            )
        
        if doc.uploaded_by != current_user.id and current_user.role not in ["admin", "reviewer"]:
            raise HTTPException(
                status_code=403,
                detail={"status": "error", "message": "You don't have permission to delete this document"}
            )
        
        doc_title = doc.title
        
        log_audit_action(
            db=db,
            action=AuditAction.DELETE,
            target_type="document",
            target_id=document_id,
            user_id=current_user.id,
            metadata={"title": doc_title},
            request=request
        )
        
        db.query(DocumentVersion).filter(DocumentVersion.document_id == document_id).delete()
        db.query(Workflow).filter(Workflow.document_id == document_id).delete()
        db.delete(doc)
        db.commit()
        
        logger.info(f"Deleted document {document_id} by user {current_user.id}")
        
        return {
            "status": "success",
            "message": "Document deleted successfully"
        }
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Error deleting document {document_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to delete document: {str(e)}"}
        )


@router.get("/analytics/portfolio")
async def get_portfolio_analytics(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Get portfolio-level analytics aggregating all documents.
    
    Returns:
        Portfolio analytics including total commitments, ESG breakdown,
        workflow distribution, and maturity timeline.
    """
    from sqlalchemy import func
    from collections import defaultdict
    
    try:
        total_documents = db.query(Document).count()
        
        commitment_result = db.query(
            func.sum(Document.total_commitment).label("total"),
            Document.currency
        ).filter(
            Document.total_commitment.isnot(None)
        ).group_by(Document.currency).all()
        
        commitments_by_currency = {}
        total_commitment_usd = Decimal("0")
        for row in commitment_result:
            if row.currency:
                amount = float(row.total) if row.total else 0
                commitments_by_currency[row.currency] = amount
                if row.currency == "USD":
                    total_commitment_usd += Decimal(str(amount))
        
        sustainability_count = db.query(Document).filter(
            Document.sustainability_linked == True
        ).count()
        sustainability_percentage = (sustainability_count / total_documents * 100) if total_documents > 0 else 0
        
        workflow_states = db.query(
            Workflow.state,
            func.count(Workflow.id).label("count")
        ).group_by(Workflow.state).all()
        
        workflow_distribution = {row.state: row.count for row in workflow_states}
        
        maturity_data = []
        documents_with_dates = db.query(
            Document.id,
            Document.title,
            Document.borrower_name,
            Document.agreement_date,
            Document.total_commitment,
            Document.currency,
            Document.sustainability_linked
        ).filter(
            Document.agreement_date.isnot(None)
        ).order_by(Document.agreement_date.desc()).limit(50).all()
        
        for doc in documents_with_dates:
            maturity_data.append({
                "id": doc.id,
                "title": doc.title,
                "borrower_name": doc.borrower_name,
                "agreement_date": doc.agreement_date.isoformat() if doc.agreement_date else None,
                "total_commitment": float(doc.total_commitment) if doc.total_commitment else None,
                "currency": doc.currency,
                "sustainability_linked": doc.sustainability_linked
            })
        
        esg_breakdown = {
            "sustainability_linked": sustainability_count,
            "non_sustainability": total_documents - sustainability_count,
            "esg_score_distribution": {}
        }
        
        docs_with_esg = db.query(Document).filter(
            Document.esg_metadata.isnot(None)
        ).all()
        
        for doc in docs_with_esg:
            if doc.esg_metadata:
                kpis = doc.esg_metadata.get("kpis", [])
                for kpi in kpis:
                    category = kpi.get("category", "Other")
                    if category not in esg_breakdown["esg_score_distribution"]:
                        esg_breakdown["esg_score_distribution"][category] = 0
                    esg_breakdown["esg_score_distribution"][category] += 1
        
        recent_activity = db.query(Document).options(
            joinedload(Document.workflow)
        ).order_by(Document.updated_at.desc()).limit(5).all()
        
        recent_docs = []
        for doc in recent_activity:
            recent_docs.append({
                "id": doc.id,
                "title": doc.title,
                "borrower_name": doc.borrower_name,
                "workflow_state": doc.workflow.state if doc.workflow else None,
                "updated_at": doc.updated_at.isoformat() if doc.updated_at else None
            })
        
        return {
            "status": "success",
            "analytics": {
                "summary": {
                    "total_documents": total_documents,
                    "total_commitment_usd": float(total_commitment_usd),
                    "commitments_by_currency": commitments_by_currency,
                    "sustainability_linked_count": sustainability_count,
                    "sustainability_percentage": round(sustainability_percentage, 1)
                },
                "workflow_distribution": workflow_distribution,
                "esg_breakdown": esg_breakdown,
                "maturity_timeline": maturity_data,
                "recent_activity": recent_docs
            }
        }
    except Exception as e:
        logger.error(f"Error fetching portfolio analytics: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to fetch analytics: {str(e)}"}
        )


@router.get("/analytics/dashboard")
async def get_dashboard_analytics(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Get enhanced dashboard analytics with activity feed and key metrics.
    
    Returns:
        Dashboard analytics including key metrics, activity feed from audit logs,
        pending approvals, and trend indicators.
    """
    from sqlalchemy import func
    from datetime import timedelta
    
    try:
        now = datetime.utcnow()
        week_ago = now - timedelta(days=7)
        two_weeks_ago = now - timedelta(days=14)
        
        total_documents = db.query(Document).count()
        
        docs_this_week = db.query(Document).filter(
            Document.created_at >= week_ago
        ).count()
        
        docs_last_week = db.query(Document).filter(
            Document.created_at >= two_weeks_ago,
            Document.created_at < week_ago
        ).count()
        
        pending_review = db.query(Workflow).filter(
            Workflow.state == WorkflowState.UNDER_REVIEW.value
        ).count()
        
        approved_this_week = db.query(Workflow).filter(
            Workflow.state == WorkflowState.APPROVED.value,
            Workflow.updated_at >= week_ago
        ).count()
        
        published_count = db.query(Workflow).filter(
            Workflow.state == WorkflowState.PUBLISHED.value
        ).count()
        
        draft_count = db.query(Workflow).filter(
            Workflow.state == WorkflowState.DRAFT.value
        ).count()
        
        commitment_result = db.query(
            func.sum(Document.total_commitment)
        ).filter(
            Document.currency == "USD",
            Document.total_commitment.isnot(None)
        ).scalar()
        total_commitment_usd = float(commitment_result) if commitment_result else 0
        
        sustainability_count = db.query(Document).filter(
            Document.sustainability_linked == True
        ).count()
        sustainability_percentage = (sustainability_count / total_documents * 100) if total_documents > 0 else 0
        
        activity_logs = db.query(AuditLog).options(
            joinedload(AuditLog.user)
        ).order_by(AuditLog.occurred_at.desc()).limit(15).all()
        
        activity_feed = []
        for log in activity_logs:
            action_descriptions = {
                "create": "created",
                "update": "updated",
                "delete": "deleted",
                "approve": "approved",
                "reject": "rejected",
                "publish": "published",
                "export": "exported",
                "submit_review": "submitted for review",
                "login": "logged in",
                "logout": "logged out",
                "broadcast": "broadcast message"
            }
            
            action_text = action_descriptions.get(log.action, log.action)
            target_name = None
            if log.action_metadata:
                target_name = log.action_metadata.get("title") or log.action_metadata.get("name")
            
            activity_feed.append({
                "id": log.id,
                "action": log.action,
                "action_text": action_text,
                "target_type": log.target_type,
                "target_id": log.target_id,
                "target_name": target_name,
                "user_name": log.user.display_name if log.user else "System",
                "user_id": log.user_id,
                "occurred_at": log.occurred_at.isoformat() if log.occurred_at else None,
                "metadata": log.action_metadata
            })
        
        docs_trend = 0
        if docs_last_week > 0:
            docs_trend = round(((docs_this_week - docs_last_week) / docs_last_week) * 100, 1)
        elif docs_this_week > 0:
            docs_trend = 100.0
        
        return {
            "status": "success",
            "dashboard": {
                "key_metrics": {
                    "total_documents": total_documents,
                    "docs_this_week": docs_this_week,
                    "docs_trend_percent": docs_trend,
                    "pending_review": pending_review,
                    "approved_this_week": approved_this_week,
                    "published_count": published_count,
                    "draft_count": draft_count,
                    "total_commitment_usd": total_commitment_usd,
                    "sustainability_count": sustainability_count,
                    "sustainability_percentage": round(sustainability_percentage, 1)
                },
                "activity_feed": activity_feed,
                "last_updated": now.isoformat()
            }
        }
    except Exception as e:
        logger.error(f"Error fetching dashboard analytics: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to fetch dashboard analytics: {str(e)}"}
        )


@router.get("/analytics/template-metrics")
async def get_template_metrics(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Get template usage metrics for dashboard.
    
    Returns:
        Template metrics including:
        - Total generations
        - Success rate
        - Average generation time
        - Most used templates
    """
    from sqlalchemy import func
    from app.db.models import GeneratedDocument, GeneratedDocumentStatus
    
    try:
        # Total generations
        total_generations = db.query(GeneratedDocument).count()
        
        # Success rate (approved or executed / total)
        successful_generations = db.query(GeneratedDocument).filter(
            GeneratedDocument.status.in_([
                GeneratedDocumentStatus.APPROVED.value,
                GeneratedDocumentStatus.EXECUTED.value
            ])
        ).count()
        success_rate = (successful_generations / total_generations * 100) if total_generations > 0 else 0
        
        # Average generation time (if available in metadata)
        # For now, we'll use a placeholder - this would need to be tracked during generation
        avg_generation_time = 0.0
        if total_generations > 0:
            # Calculate from created_at timestamps if we track start/end times
            # For now, return a default estimate
            avg_generation_time = 45.0  # seconds
        
        # Most used templates
        template_usage = db.query(
            GeneratedDocument.template_id,
            func.count(GeneratedDocument.id).label('usage_count')
        ).filter(
            GeneratedDocument.template_id.isnot(None)
        ).group_by(GeneratedDocument.template_id).order_by(
            func.count(GeneratedDocument.id).desc()
        ).limit(5).all()
        
        most_used = []
        for template_id, usage_count in template_usage:
            template = db.query(LMATemplate).filter(LMATemplate.id == template_id).first()
            if template:
                most_used.append({
                    "template_id": template.id,
                    "template_name": template.name,
                    "template_category": template.category,
                    "usage_count": usage_count
                })
        
        return {
            "status": "success",
            "template_metrics": {
                "total_generations": total_generations,
                "success_rate": round(success_rate, 1),
                "average_generation_time_seconds": round(avg_generation_time, 1),
                "most_used_templates": most_used
            }
        }
    except Exception as e:
        logger.error(f"Error fetching template metrics: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to fetch template metrics: {str(e)}"}
        )


@router.get("/analytics/charts")
async def get_chart_analytics(
    range: str = Query("7d", description="Date range: 7d, 30d, 90d, or all"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Get time-series chart data for dashboard visualizations.
    
    Args:
        range: Date range filter - 7d (week), 30d (month), 90d (quarter), or all
        
    Returns:
        Chart data including document trends over time and workflow pipeline data.
    """
    from sqlalchemy import func, cast, Date
    from datetime import timedelta
    from collections import defaultdict
    
    try:
        now = datetime.utcnow()
        
        range_days = {
            "7d": 7,
            "30d": 30,
            "90d": 90,
            "all": 365
        }
        days = range_days.get(range, 7)
        start_date = now - timedelta(days=days)
        
        if days <= 7:
            group_format = "%Y-%m-%d"
            date_labels = [(now - timedelta(days=i)).strftime("%b %d") for i in range(days, -1, -1)]
        elif days <= 30:
            group_format = "%Y-%m-%d"
            date_labels = [(now - timedelta(days=i)).strftime("%b %d") for i in range(days, -1, -1)]
        else:
            group_format = "%Y-%U"
            weeks = days // 7
            date_labels = [(now - timedelta(weeks=i)).strftime("Week %U") for i in range(weeks, -1, -1)]
        
        docs_by_date = defaultdict(int)
        
        documents = db.query(
            Document.created_at
        ).filter(
            Document.created_at >= start_date
        ).all()
        
        for doc in documents:
            if doc.created_at:
                if days <= 30:
                    date_key = doc.created_at.strftime("%b %d")
                else:
                    date_key = doc.created_at.strftime("Week %U")
                docs_by_date[date_key] += 1
        
        document_trend = []
        cumulative = 0
        for label in date_labels:
            count = docs_by_date.get(label, 0)
            cumulative += count
            document_trend.append({
                "date": label,
                "documents": count,
                "cumulative": cumulative
            })
        
        workflow_states = db.query(
            Workflow.state,
            func.count(Workflow.id).label('count')
        ).group_by(Workflow.state).all()
        
        workflow_colors = {
            "draft": "#64748b",
            "under_review": "#f59e0b",
            "approved": "#10b981",
            "published": "#3b82f6",
            "archived": "#6b7280"
        }
        
        workflow_pipeline = []
        for state, count in workflow_states:
            workflow_pipeline.append({
                "state": state,
                "label": state.replace("_", " ").title(),
                "count": count,
                "color": workflow_colors.get(state, "#64748b")
            })
        
        commitments_by_date = defaultdict(float)
        
        commitment_docs = db.query(
            Document.created_at,
            Document.total_commitment,
            Document.currency
        ).filter(
            Document.created_at >= start_date,
            Document.total_commitment.isnot(None)
        ).all()
        
        for doc in commitment_docs:
            if doc.created_at and doc.total_commitment:
                if days <= 30:
                    date_key = doc.created_at.strftime("%b %d")
                else:
                    date_key = doc.created_at.strftime("Week %U")
                amount = float(doc.total_commitment)
                commitments_by_date[date_key] += amount
        
        commitment_trend = []
        cumulative_commitment = 0
        for label in date_labels:
            amount = commitments_by_date.get(label, 0)
            cumulative_commitment += amount
            commitment_trend.append({
                "date": label,
                "amount": round(amount, 2),
                "cumulative": round(cumulative_commitment, 2)
            })
        
        action_counts = db.query(
            AuditLog.action,
            func.count(AuditLog.id).label('count')
        ).filter(
            AuditLog.occurred_at >= start_date
        ).group_by(AuditLog.action).all()
        
        activity_by_type = []
        for action, count in action_counts:
            activity_by_type.append({
                "action": action,
                "label": action.replace("_", " ").title(),
                "count": count
            })
        
        return {
            "status": "success",
            "charts": {
                "date_range": range,
                "start_date": start_date.isoformat(),
                "end_date": now.isoformat(),
                "document_trend": document_trend,
                "workflow_pipeline": workflow_pipeline,
                "commitment_trend": commitment_trend,
                "activity_by_type": activity_by_type
            }
        }
    except Exception as e:
        logger.error(f"Error fetching chart analytics: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to fetch chart analytics: {str(e)}"}
        )


class WorkflowTransitionRequest(BaseModel):
    """Request model for workflow transitions."""
    comment: Optional[str] = Field(None, description="Optional comment for the transition")
    assigned_to: Optional[int] = Field(None, description="User ID to assign the review to")
    priority: Optional[str] = Field(None, description="Priority level: low, normal, high, urgent")
    due_date: Optional[str] = Field(None, description="Due date for review in ISO format")


class WorkflowRejectRequest(BaseModel):
    """Request model for rejecting a document."""
    reason: str = Field(..., description="Reason for rejection")
    comment: Optional[str] = Field(None, description="Additional comment")


def check_workflow_permission(user: User, required_roles: List[str]) -> bool:
    """Check if user has one of the required roles."""
    return user.role in required_roles


def get_workflow_or_404(db: Session, document_id: int) -> Workflow:
    """Get workflow for a document or raise 404."""
    workflow = db.query(Workflow).filter(Workflow.document_id == document_id).first()
    if not workflow:
        raise HTTPException(
            status_code=404,
            detail={"status": "error", "message": "Workflow not found for this document"}
        )
    return workflow


@router.post("/documents/{document_id}/workflow/submit")
async def submit_for_review(
    document_id: int,
    request: Request,
    transition_request: WorkflowTransitionRequest = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """Submit a document for review.
    
    Transitions the workflow from Draft to Under Review.
    Required roles: analyst, reviewer, admin
    """
    try:
        if not check_workflow_permission(current_user, ["analyst", "reviewer", "admin"]):
            raise HTTPException(
                status_code=403,
                detail={"status": "error", "message": "You don't have permission to submit documents for review"}
            )
        
        workflow = get_workflow_or_404(db, document_id)
        
        if workflow.state != WorkflowState.DRAFT.value:
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": f"Cannot submit for review: document is in '{workflow.state}' state, must be 'draft'"}
            )
        
        previous_state = workflow.state
        workflow.state = WorkflowState.UNDER_REVIEW.value
        workflow.submitted_at = datetime.utcnow()
        workflow.rejection_reason = None
        
        # Check for policy decisions that might affect workflow priority
        # Query for recent policy decision for this document's transaction
        doc = db.query(Document).filter(Document.id == document_id).first()
        if doc:
            # Try to get transaction ID from document metadata
            transaction_id = None
            if doc.deal_id:
                transaction_id = doc.deal_id
            elif doc.loan_identification_number:
                transaction_id = doc.loan_identification_number
            
            if transaction_id:
                recent_policy_decision = db.query(PolicyDecisionModel).filter(
                    PolicyDecisionModel.transaction_id == transaction_id,
                    PolicyDecisionModel.transaction_type == "facility_creation"
                ).order_by(PolicyDecisionModel.created_at.desc()).first()
                
                if recent_policy_decision and recent_policy_decision.decision == "FLAG":
                    # FLAG decision: ensure high priority
                    if not transition_request or not transition_request.priority:
                        workflow.priority = "high"
                        logger.info(
                            f"Workflow for document {document_id} set to high priority due to FLAG policy decision: "
                            f"{recent_policy_decision.rule_applied}"
                        )
        
        if transition_request:
            if transition_request.assigned_to:
                assignee = db.query(User).filter(User.id == transition_request.assigned_to).first()
                if assignee and assignee.role in ["reviewer", "admin"]:
                    workflow.assigned_to = transition_request.assigned_to
            if transition_request.priority:
                workflow.priority = transition_request.priority
            if transition_request.due_date:
                try:
                    workflow.due_date = datetime.fromisoformat(transition_request.due_date.replace("Z", "+00:00"))
                except ValueError:
                    pass
        
        log_audit_action(
            db=db,
            action=AuditAction.UPDATE,
            target_type="workflow",
            target_id=workflow.id,
            user_id=current_user.id,
            metadata={"document_id": document_id, "transition": "submit", "from_state": previous_state, "to_state": WorkflowState.UNDER_REVIEW.value},
            request=request
        )
        
        db.commit()
        db.refresh(workflow)
        
        logger.info(f"Document {document_id} submitted for review by user {current_user.id}")
        
        return {
            "status": "success",
            "message": "Document submitted for review",
            "workflow": workflow.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Error submitting document {document_id} for review: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to submit for review: {str(e)}"}
        )


@router.post("/documents/{document_id}/workflow/approve")
async def approve_document(
    document_id: int,
    request: Request,
    transition_request: WorkflowTransitionRequest = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """Approve a document under review.
    
    Transitions the workflow from Under Review to Approved.
    Required roles: reviewer, admin
    """
    try:
        if not check_workflow_permission(current_user, ["reviewer", "admin"]):
            raise HTTPException(
                status_code=403,
                detail={"status": "error", "message": "You don't have permission to approve documents"}
            )
        
        workflow = get_workflow_or_404(db, document_id)
        
        if workflow.state != WorkflowState.UNDER_REVIEW.value:
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": f"Cannot approve: document is in '{workflow.state}' state, must be 'under_review'"}
            )
        
        previous_state = workflow.state
        workflow.state = WorkflowState.APPROVED.value
        workflow.approved_at = datetime.utcnow()
        workflow.approved_by = current_user.id
        
        log_audit_action(
            db=db,
            action=AuditAction.APPROVE,
            target_type="workflow",
            target_id=workflow.id,
            user_id=current_user.id,
            metadata={"document_id": document_id, "transition": "approve", "from_state": previous_state, "to_state": WorkflowState.APPROVED.value},
            request=request
        )
        
        db.commit()
        db.refresh(workflow)
        
        logger.info(f"Document {document_id} approved by user {current_user.id}")
        
        return {
            "status": "success",
            "message": "Document approved",
            "workflow": workflow.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Error approving document {document_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to approve document: {str(e)}"}
        )


@router.post("/documents/{document_id}/workflow/reject")
async def reject_document(
    document_id: int,
    reject_request: WorkflowRejectRequest,
    request: Request,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """Reject a document under review.
    
    Transitions the workflow from Under Review back to Draft.
    Required roles: reviewer, admin
    """
    try:
        if not check_workflow_permission(current_user, ["reviewer", "admin"]):
            raise HTTPException(
                status_code=403,
                detail={"status": "error", "message": "You don't have permission to reject documents"}
            )
        
        workflow = get_workflow_or_404(db, document_id)
        
        if workflow.state != WorkflowState.UNDER_REVIEW.value:
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": f"Cannot reject: document is in '{workflow.state}' state, must be 'under_review'"}
            )
        
        previous_state = workflow.state
        workflow.state = WorkflowState.DRAFT.value
        workflow.rejection_reason = reject_request.reason
        workflow.approved_at = None
        workflow.approved_by = None
        workflow.assigned_to = None
        workflow.due_date = None
        
        log_audit_action(
            db=db,
            action=AuditAction.REJECT,
            target_type="workflow",
            target_id=workflow.id,
            user_id=current_user.id,
            metadata={"document_id": document_id, "transition": "reject", "from_state": previous_state, "to_state": WorkflowState.DRAFT.value, "reason": reject_request.reason},
            request=request
        )
        
        db.commit()
        db.refresh(workflow)
        
        logger.info(f"Document {document_id} rejected by user {current_user.id}: {reject_request.reason}")
        
        return {
            "status": "success",
            "message": "Document rejected and returned to draft",
            "workflow": workflow.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Error rejecting document {document_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to reject document: {str(e)}"}
        )


@router.post("/documents/{document_id}/workflow/publish")
async def publish_document(
    document_id: int,
    request: Request,
    transition_request: WorkflowTransitionRequest = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """Publish an approved document.
    
    Transitions the workflow from Approved to Published.
    Required roles: reviewer, admin
    """
    try:
        if not check_workflow_permission(current_user, ["reviewer", "admin"]):
            raise HTTPException(
                status_code=403,
                detail={"status": "error", "message": "You don't have permission to publish documents"}
            )
        
        workflow = get_workflow_or_404(db, document_id)
        
        if workflow.state != WorkflowState.APPROVED.value:
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": f"Cannot publish: document is in '{workflow.state}' state, must be 'approved'"}
            )
        
        previous_state = workflow.state
        workflow.state = WorkflowState.PUBLISHED.value
        workflow.published_at = datetime.utcnow()
        
        log_audit_action(
            db=db,
            action=AuditAction.PUBLISH,
            target_type="workflow",
            target_id=workflow.id,
            user_id=current_user.id,
            metadata={"document_id": document_id, "transition": "publish", "from_state": previous_state, "to_state": WorkflowState.PUBLISHED.value},
            request=request
        )
        
        db.commit()
        db.refresh(workflow)
        
        logger.info(f"Document {document_id} published by user {current_user.id}")
        
        return {
            "status": "success",
            "message": "Document published",
            "workflow": workflow.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Error publishing document {document_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to publish document: {str(e)}"}
        )


@router.post("/documents/{document_id}/workflow/archive")
async def archive_document(
    document_id: int,
    request: Request,
    transition_request: WorkflowTransitionRequest = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """Archive a document.
    
    Transitions the workflow from any state to Archived.
    Required roles: reviewer, admin
    """
    try:
        if not check_workflow_permission(current_user, ["reviewer", "admin"]):
            raise HTTPException(
                status_code=403,
                detail={"status": "error", "message": "You don't have permission to archive documents"}
            )
        
        workflow = get_workflow_or_404(db, document_id)
        
        if workflow.state == WorkflowState.ARCHIVED.value:
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": "Document is already archived"}
            )
        
        previous_state = workflow.state
        workflow.state = WorkflowState.ARCHIVED.value
        
        log_audit_action(
            db=db,
            action=AuditAction.UPDATE,
            target_type="workflow",
            target_id=workflow.id,
            user_id=current_user.id,
            metadata={"document_id": document_id, "transition": "archive", "from_state": previous_state, "to_state": WorkflowState.ARCHIVED.value},
            request=request
        )
        
        db.commit()
        db.refresh(workflow)
        
        logger.info(f"Document {document_id} archived by user {current_user.id}")
        
        return {
            "status": "success",
            "message": "Document archived",
            "workflow": workflow.to_dict()
        }
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Error archiving document {document_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to archive document: {str(e)}"}
        )


@router.get("/documents/{document_id}/workflow")
async def get_document_workflow(
    document_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Get the current workflow state for a document.
    
    Returns workflow details including available actions based on current state.
    """
    try:
        workflow = get_workflow_or_404(db, document_id)
        
        available_actions = []
        state = workflow.state
        
        if state == WorkflowState.DRAFT.value:
            available_actions = ["submit"]
        elif state == WorkflowState.UNDER_REVIEW.value:
            available_actions = ["approve", "reject"]
        elif state == WorkflowState.APPROVED.value:
            available_actions = ["publish", "archive"]
        elif state == WorkflowState.PUBLISHED.value:
            available_actions = ["archive"]
        
        result = workflow.to_dict()
        result["available_actions"] = available_actions
        
        if workflow.approved_by:
            approver = db.query(User).filter(User.id == workflow.approved_by).first()
            result["approved_by_name"] = approver.display_name if approver else None
        
        if workflow.assigned_to:
            assignee = db.query(User).filter(User.id == workflow.assigned_to).first()
            result["assigned_to_name"] = assignee.display_name if assignee else None
        
        return {
            "status": "success",
            "workflow": result
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting workflow for document {document_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to get workflow: {str(e)}"}
        )


@router.get("/audit-logs")
async def list_audit_logs(
    action: Optional[str] = Query(None, description="Filter by action type (create, update, delete, approve, reject, publish, export, login, logout, broadcast)"),
    target_type: Optional[str] = Query(None, description="Filter by target type (document, workflow, user)"),
    target_id: Optional[int] = Query(None, description="Filter by target ID"),
    user_id: Optional[int] = Query(None, description="Filter by user ID"),
    start_date: Optional[str] = Query(None, description="Filter logs from this date (ISO format)"),
    end_date: Optional[str] = Query(None, description="Filter logs until this date (ISO format)"),
    limit: int = Query(50, ge=1, le=500, description="Maximum number of results"),
    offset: int = Query(0, ge=0, description="Offset for pagination"),
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """List audit logs with optional filtering.
    
    Returns a paginated list of audit log entries. Only accessible by authenticated users.
    Admins and reviewers can see all logs; other users can only see logs related to their actions.
    """
    try:
        query = db.query(AuditLog).options(joinedload(AuditLog.user))
        
        if current_user.role not in ["admin", "reviewer"]:
            query = query.filter(AuditLog.user_id == current_user.id)
        
        if action:
            valid_actions = [a.value for a in AuditAction]
            if action not in valid_actions:
                raise HTTPException(
                    status_code=400,
                    detail={"status": "error", "message": f"Invalid action: {action}. Must be one of: {', '.join(valid_actions)}"}
                )
            query = query.filter(AuditLog.action == action)
        
        if target_type:
            query = query.filter(AuditLog.target_type == target_type)
        
        if target_id:
            query = query.filter(AuditLog.target_id == target_id)
        
        if user_id:
            if current_user.role in ["admin", "reviewer"]:
                query = query.filter(AuditLog.user_id == user_id)
        
        if start_date:
            try:
                start_dt = datetime.fromisoformat(start_date.replace("Z", "+00:00"))
                query = query.filter(AuditLog.occurred_at >= start_dt)
            except ValueError:
                raise HTTPException(
                    status_code=400,
                    detail={"status": "error", "message": f"Invalid start_date format: {start_date}. Use ISO format."}
                )
        
        if end_date:
            try:
                end_dt = datetime.fromisoformat(end_date.replace("Z", "+00:00"))
                query = query.filter(AuditLog.occurred_at <= end_dt)
            except ValueError:
                raise HTTPException(
                    status_code=400,
                    detail={"status": "error", "message": f"Invalid end_date format: {end_date}. Use ISO format."}
                )
        
        total = query.count()
        
        logs = query.order_by(AuditLog.occurred_at.desc()).offset(offset).limit(limit).all()
        
        result = []
        for log in logs:
            log_dict = log.to_dict()
            log_dict["user_name"] = log.user.display_name if log.user else None
            log_dict["user_email"] = log.user.email if log.user else None
            result.append(log_dict)
        
        return {
            "status": "success",
            "total": total,
            "limit": limit,
            "offset": offset,
            "logs": result
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error listing audit logs: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to list audit logs: {str(e)}"}
        )


@router.get("/documents/{document_id}/audit-logs")
async def list_document_audit_logs(
    document_id: int,
    limit: int = Query(50, ge=1, le=200, description="Maximum number of results"),
    offset: int = Query(0, ge=0, description="Offset for pagination"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """List audit logs for a specific document.
    
    Returns audit log entries related to a specific document, including workflow changes.
    """
    try:
        doc = db.query(Document).filter(Document.id == document_id).first()
        if not doc:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": "Document not found"}
            )
        
        workflow = db.query(Workflow).filter(Workflow.document_id == document_id).first()
        workflow_id = workflow.id if workflow else None
        
        query = db.query(AuditLog).options(joinedload(AuditLog.user))
        
        if workflow_id:
            query = query.filter(
                ((AuditLog.target_type == "document") & (AuditLog.target_id == document_id)) |
                ((AuditLog.target_type == "workflow") & (AuditLog.target_id == workflow_id))
            )
        else:
            query = query.filter(
                (AuditLog.target_type == "document") & (AuditLog.target_id == document_id)
            )
        
        total = query.count()
        
        logs = query.order_by(AuditLog.occurred_at.desc()).offset(offset).limit(limit).all()
        
        result = []
        for log in logs:
            log_dict = log.to_dict()
            log_dict["user_name"] = log.user.display_name if log.user else None
            result.append(log_dict)
        
        return {
            "status": "success",
            "document_id": document_id,
            "total": total,
            "limit": limit,
            "offset": offset,
            "logs": result
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error listing audit logs for document {document_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to list document audit logs: {str(e)}"}
        )


def flatten_agreement_data(agreement_data: dict) -> dict:
    """Flatten nested agreement data structure for tabular export.
    
    Args:
        agreement_data: The nested agreement data from extraction.
        
    Returns:
        Flattened dictionary suitable for DataFrame/CSV export.
    """
    flat = {}
    
    flat["agreement_date"] = agreement_data.get("agreement_date")
    flat["governing_law"] = agreement_data.get("governing_law")
    flat["amendment_number"] = agreement_data.get("amendment_number")
    
    parties = agreement_data.get("parties", [])
    borrowers = [p for p in parties if isinstance(p.get("role", ""), str) and "borrower" in p.get("role", "").lower()]
    lenders = [p for p in parties if p.get("role") in ["Lender", "Administrative Agent"]]
    
    if borrowers:
        flat["borrower_name"] = borrowers[0].get("name") or borrowers[0].get("legal_name")
        flat["borrower_lei"] = borrowers[0].get("lei")
        flat["borrower_jurisdiction"] = borrowers[0].get("jurisdiction")
    
    if lenders:
        flat["lender_count"] = len(lenders)
        flat["administrative_agent"] = next(
            (p.get("name") or p.get("legal_name") for p in lenders if p.get("role") == "Administrative Agent"),
            None
        )
    
    facilities = agreement_data.get("facilities", [])
    flat["facility_count"] = len(facilities)
    
    total_commitment = Decimal("0")
    currency = None
    for i, facility in enumerate(facilities):
        if not isinstance(facility, dict):
            continue
        prefix = f"facility_{i+1}_"
        flat[f"{prefix}type"] = facility.get("facility_type")
        flat[f"{prefix}name"] = facility.get("facility_name")
        
        commitment = facility.get("commitment_amount") or facility.get("commitment")
        if commitment and isinstance(commitment, dict):
            amount = commitment.get("amount")
            if amount:
                flat[f"{prefix}commitment_amount"] = float(amount)
                total_commitment += Decimal(str(amount))
            curr = commitment.get("currency")
            if curr:
                flat[f"{prefix}currency"] = curr
                if not currency:
                    currency = curr
        
        flat[f"{prefix}maturity_date"] = facility.get("maturity_date")
        
        interest = facility.get("interest_terms") or facility.get("interest_rate_payout")
        if interest and isinstance(interest, dict):
            floating = interest.get("rate_option") or interest.get("floating_rate_option")
            if floating and isinstance(floating, dict):
                flat[f"{prefix}benchmark_rate"] = floating.get("benchmark") or floating.get("benchmark_rate")
                flat[f"{prefix}spread_bps"] = floating.get("spread_bps") or floating.get("spread")
            pf = interest.get("payment_frequency")
            if pf and isinstance(pf, dict):
                flat[f"{prefix}payment_frequency"] = f"{pf.get('period_multiplier')} {pf.get('period')}"
            else:
                flat[f"{prefix}payment_frequency"] = pf
    
    flat["total_commitment"] = float(total_commitment) if total_commitment > 0 else None
    flat["currency"] = currency
    
    sustainability = agreement_data.get("sustainability_provisions")
    if sustainability and isinstance(sustainability, dict):
        flat["sustainability_linked"] = sustainability.get("is_sustainability_linked", False)
        kpis = sustainability.get("esg_kpis", [])
        if kpis:
            flat["esg_kpi_count"] = len(kpis)
            flat["esg_kpis"] = "; ".join([k.get("name", "") for k in kpis if k.get("name")])
        margin = sustainability.get("margin_adjustment")
        if margin:
            flat["margin_adjustment_bps"] = margin.get("basis_points")
    else:
        flat["sustainability_linked"] = False
    
    covenants = agreement_data.get("financial_covenants", [])
    if covenants:
        flat["covenant_count"] = len(covenants)
        flat["covenants"] = "; ".join([c.get("name", "") for c in covenants if c.get("name")])
    
    return flat


def agreement_to_dataframe(agreement_data: dict, include_raw: bool = False) -> pd.DataFrame:
    """Convert agreement data to a pandas DataFrame.
    
    Args:
        agreement_data: The agreement data from extraction.
        include_raw: Whether to include a column with the raw JSON.
        
    Returns:
        DataFrame with one row containing the flattened data.
    """
    flat = flatten_agreement_data(agreement_data)
    
    if include_raw:
        flat["raw_json"] = json.dumps(agreement_data, default=str)
    
    df = pd.DataFrame([flat])
    return df


def facilities_to_dataframe(agreement_data: dict) -> pd.DataFrame:
    """Convert facilities from agreement data to a DataFrame.
    
    Args:
        agreement_data: The agreement data from extraction.
        
    Returns:
        DataFrame with one row per facility.
    """
    facilities = agreement_data.get("facilities", [])
    if not facilities:
        return pd.DataFrame()
    
    rows = []
    for facility in facilities:
        if not isinstance(facility, dict):
            continue
        row = {
            "facility_type": facility.get("facility_type"),
            "facility_name": facility.get("facility_name"),
            "maturity_date": facility.get("maturity_date"),
        }
        
        commitment = facility.get("commitment_amount") or facility.get("commitment")
        if commitment and isinstance(commitment, dict):
            row["commitment_amount"] = commitment.get("amount")
            row["currency"] = commitment.get("currency")
        
        interest = facility.get("interest_terms") or facility.get("interest_rate_payout")
        if interest and isinstance(interest, dict):
            floating = interest.get("rate_option") or interest.get("floating_rate_option")
            if floating and isinstance(floating, dict):
                row["benchmark_rate"] = floating.get("benchmark") or floating.get("benchmark_rate")
                row["spread_bps"] = floating.get("spread_bps") or floating.get("spread")
            pf = interest.get("payment_frequency")
            if pf and isinstance(pf, dict):
                row["payment_frequency"] = f"{pf.get('period_multiplier')} {pf.get('period')}"
            else:
                row["payment_frequency"] = pf
        
        rows.append(row)
    
    return pd.DataFrame(rows)


def parties_to_dataframe(agreement_data: dict) -> pd.DataFrame:
    """Convert parties from agreement data to a DataFrame.
    
    Args:
        agreement_data: The agreement data from extraction.
        
    Returns:
        DataFrame with one row per party.
    """
    parties = agreement_data.get("parties", [])
    if not parties:
        return pd.DataFrame()
    
    rows = []
    for party in parties:
        rows.append({
            "name": party.get("name") or party.get("legal_name"),
            "role": party.get("role"),
            "lei": party.get("lei"),
            "jurisdiction": party.get("jurisdiction"),
        })
    
    return pd.DataFrame(rows)


@router.get("/documents/{document_id}/export")
async def export_document(
    document_id: int,
    format: str = Query("json", description="Export format: json, csv, or excel"),
    version_id: Optional[int] = Query(None, description="Specific version ID to export (defaults to current version)"),
    request: Request = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """Export document data in various formats.
    
    Args:
        document_id: The document ID.
        format: Export format (json, csv, excel).
        version_id: Optional specific version to export.
        request: The HTTP request.
        db: Database session.
        current_user: The current user (optional).
        
    Returns:
        The exported data as a file download.
    """
    format = format.lower()
    if format not in ["json", "csv", "excel", "xlsx"]:
        raise HTTPException(
            status_code=400,
            detail={"status": "error", "message": f"Invalid format: {format}. Supported: json, csv, excel"}
        )
    
    if format == "xlsx":
        format = "excel"
    
    try:
        doc = db.query(Document).options(
            joinedload(Document.versions)
        ).filter(Document.id == document_id).first()
        
        if not doc:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": "Document not found"}
            )
        
        if version_id:
            version = next((v for v in doc.versions if v.id == version_id), None)
            if not version:
                raise HTTPException(
                    status_code=404,
                    detail={"status": "error", "message": f"Version {version_id} not found"}
                )
        else:
            version = next((v for v in doc.versions if v.id == doc.current_version_id), None)
            if not version and doc.versions:
                version = max(doc.versions, key=lambda v: v.version_number)
        
        if not version:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": "No versions found for this document"}
            )
        
        agreement_data = version.extracted_data
        safe_title = "".join(c for c in doc.title if c.isalnum() or c in " -_").strip()[:50]
        filename_base = f"{safe_title}_v{version.version_number}"
        
        if format == "json":
            output = io.BytesIO()
            json_data = json.dumps(agreement_data, indent=2, default=str)
            output.write(json_data.encode("utf-8"))
            output.seek(0)
            
            if current_user:
                log_audit_action(
                    db=db,
                    action=AuditAction.EXPORT,
                    target_type="document",
                    target_id=document_id,
                    user_id=current_user.id,
                    metadata={"format": "json", "version_id": version.id},
                    request=request
                )
                db.commit()
            
            return StreamingResponse(
                output,
                media_type="application/json",
                headers={
                    "Content-Disposition": f'attachment; filename="{filename_base}.json"'
                }
            )
        
        elif format == "csv":
            df = agreement_to_dataframe(agreement_data)
            output = io.StringIO()
            df.to_csv(output, index=False)
            output.seek(0)
            
            if current_user:
                log_audit_action(
                    db=db,
                    action=AuditAction.EXPORT,
                    target_type="document",
                    target_id=document_id,
                    user_id=current_user.id,
                    metadata={"format": "csv", "version_id": version.id},
                    request=request
                )
                db.commit()
            
            return StreamingResponse(
                io.BytesIO(output.getvalue().encode("utf-8")),
                media_type="text/csv",
                headers={
                    "Content-Disposition": f'attachment; filename="{filename_base}.csv"'
                }
            )
        
        elif format == "excel":
            output = io.BytesIO()
            
            with pd.ExcelWriter(output, engine="openpyxl") as writer:
                summary_df = agreement_to_dataframe(agreement_data)
                summary_df.to_excel(writer, sheet_name="Summary", index=False)
                
                facilities_df = facilities_to_dataframe(agreement_data)
                if not facilities_df.empty:
                    facilities_df.to_excel(writer, sheet_name="Facilities", index=False)
                
                parties_df = parties_to_dataframe(agreement_data)
                if not parties_df.empty:
                    parties_df.to_excel(writer, sheet_name="Parties", index=False)
            
            output.seek(0)
            
            if current_user:
                log_audit_action(
                    db=db,
                    action=AuditAction.EXPORT,
                    target_type="document",
                    target_id=document_id,
                    user_id=current_user.id,
                    metadata={"format": "excel", "version_id": version.id},
                    request=request
                )
                db.commit()
            
            return StreamingResponse(
                output,
                media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                headers={
                    "Content-Disposition": f'attachment; filename="{filename_base}.xlsx"'
                }
            )
    
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Error exporting document {document_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to export document: {str(e)}"}
        )


# ============================================================================
# GROUND TRUTH PROTOCOL - Loan Asset & Geospatial Verification Endpoints
# ============================================================================

from app.models.loan_asset import LoanAsset, RiskStatus
from app.agents.audit_workflow import run_full_audit, AuditResult


class CreateLoanAssetRequest(BaseModel):
    """Request model for creating a loan asset."""
    loan_id: str = Field(..., description="External loan identifier")
    document_text: str = Field(..., description="Full text of loan agreement")
    title: Optional[str] = Field(None, description="Optional title for the asset")


class RunAuditRequest(BaseModel):
    """Request model for running a full audit."""
    document_text: Optional[str] = Field(None, description="Optional new document text to re-analyze")


@router.post("/loan-assets")
async def create_loan_asset(
    request_data: CreateLoanAssetRequest,
    request: Request,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user),
    policy_service: Optional[PolicyService] = Depends(get_policy_service)
):
    """
    Create a new loan asset and run the full Ground Truth audit.
    
    This is the "Securitize & Verify" endpoint that:
    1. Extracts SPT and collateral address from document
    2. Geocodes the address
    3. Fetches satellite imagery
    4. Calculates NDVI and determines compliance status
    5. Evaluates policy compliance for securitization
    
    Args:
        request_data: Loan ID and document text
        request: HTTP request for audit logging
        db: Database session
        current_user: Authenticated user
        policy_service: Policy service for compliance evaluation (optional)
        
    Returns:
        Created loan asset with verification results
    """
    from app.models.cdm import CreditAgreement
    
    try:
        logger.info(f"Creating loan asset {request_data.loan_id}")
        
        # Try to get credit agreement from document if document_id provided
        credit_agreement = None
        if hasattr(request_data, 'document_id') and request_data.document_id:
            doc = db.query(Document).filter(Document.id == request_data.document_id).first()
            if doc and doc.current_version_id:
                version = db.query(DocumentVersion).filter(
                    DocumentVersion.id == doc.current_version_id
                ).first()
                if version and version.extracted_data:
                    try:
                        credit_agreement = CreditAgreement(**version.extracted_data)
                    except Exception as e:
                        logger.warning(f"Failed to parse credit agreement from document: {e}")
        
        # Run the full audit workflow with policy service
        audit_result = await run_full_audit(
            loan_id=request_data.loan_id,
            document_text=request_data.document_text,
            db_session=db,
            policy_service=policy_service,
            credit_agreement=credit_agreement
        )
        
        if not audit_result.loan_asset:
            raise HTTPException(
                status_code=500,
                detail={"status": "error", "message": "Failed to create loan asset"}
            )
        
        # Log the audit action
        log_audit_action(
            db=db,
            action=AuditAction.CREATE,
            target_type="loan_asset",
            target_id=audit_result.loan_asset.id,
            user_id=current_user.id if current_user else None,
            metadata={
                "loan_id": request_data.loan_id,
                "stages_completed": audit_result.stages_completed,
                "stages_failed": audit_result.stages_failed,
                "risk_status": audit_result.loan_asset.risk_status
            },
            request=request
        )
        db.commit()
        
        return {
            "status": "success",
            "message": "Loan asset created and verified",
            "loan_asset": audit_result.loan_asset.to_dict(),
            "audit": {
                "success": audit_result.success,
                "stages_completed": audit_result.stages_completed,
                "stages_failed": audit_result.stages_failed
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Error creating loan asset: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to create loan asset: {str(e)}"}
        )


@router.get("/loan-assets")
async def list_loan_assets(
    status: Optional[str] = Query(None, description="Filter by risk status"),
    limit: int = Query(50, ge=1, le=100),
    offset: int = Query(0, ge=0),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    List all loan assets with optional filtering.
    
    Args:
        status: Optional risk status filter (COMPLIANT, WARNING, BREACH, PENDING)
        limit: Maximum results
        offset: Pagination offset
        db: Database session
        current_user: Current user
        
    Returns:
        List of loan assets
    """
    try:
        query = db.query(LoanAsset)
        
        if status:
            query = query.filter(LoanAsset.risk_status == status.upper())
        
        total = query.count()
        assets = query.order_by(LoanAsset.created_at.desc()).offset(offset).limit(limit).all()
        
        return {
            "status": "success",
            "total": total,
            "limit": limit,
            "offset": offset,
            "loan_assets": [asset.to_dict() for asset in assets]
        }
        
    except Exception as e:
        logger.error(f"Error listing loan assets: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to list loan assets: {str(e)}"}
        )


@router.get("/loan-assets/{asset_id}")
async def get_loan_asset(
    asset_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Get a single loan asset by ID.
    
    Args:
        asset_id: Loan asset ID
        db: Database session
        current_user: Current user
        
    Returns:
        Loan asset details
    """
    try:
        asset = db.query(LoanAsset).filter(LoanAsset.id == asset_id).first()
        
        if not asset:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": "Loan asset not found"}
            )
        
        return {
            "status": "success",
            "loan_asset": asset.to_dict()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting loan asset {asset_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to get loan asset: {str(e)}"}
        )


@router.post("/audit/run/{asset_id}")
async def run_asset_audit(
    asset_id: int,
    request: Request,
    db: Session = Depends(get_db),
    current_user: Optional[User] = Depends(get_current_user)
):
    """
    Run or re-run the Ground Truth verification for an existing asset.
    
    This fetches fresh satellite data and recalculates NDVI.
    
    Args:
        asset_id: Loan asset ID
        request: HTTP request
        db: Database session
        current_user: Authenticated user
        
    Returns:
        Updated verification results
    """
    from app.agents.verifier import verify_asset_location
    
    try:
        asset = db.query(LoanAsset).filter(LoanAsset.id == asset_id).first()
        
        if not asset:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": "Loan asset not found"}
            )
        
        if not asset.geo_lat or not asset.geo_lon:
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": "Asset has no coordinates - cannot verify"}
            )
        
        logger.info(f"Running verification for asset {asset_id}")
        
        # Run verification
        verification = await verify_asset_location(
            lat=asset.geo_lat,
            lon=asset.geo_lon,
            threshold=asset.spt_threshold or 0.8
        )
        
        if verification.get("success"):
            ndvi_score = verification["ndvi_score"]
            asset.update_verification(ndvi_score)
        else:
            asset.risk_status = RiskStatus.ERROR
            asset.verification_error = verification.get("error", "Unknown error")
        
        # Log the audit action
        log_audit_action(
            db=db,
            action=AuditAction.UPDATE,
            target_type="loan_asset",
            target_id=asset_id,
            user_id=current_user.id if current_user else None,
            metadata={
                "action": "verification",
                "ndvi_score": verification.get("ndvi_score"),
                "risk_status": asset.risk_status,
                "data_source": verification.get("data_source")
            },
            request=request
        )
        
        db.commit()
        db.refresh(asset)
        
        return {
            "status": "success",
            "message": "Verification complete",
            "loan_asset": asset.to_dict(),
            "verification": verification
        }
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Error running audit for asset {asset_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to run audit: {str(e)}"}
        )


@router.get("/audit/status/{asset_id}")
async def get_audit_status(
    asset_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Get the current verification status of a loan asset.
    
    This is a lightweight polling endpoint for frontend status updates.
    
    Args:
        asset_id: Loan asset ID
        db: Database session
        current_user: Current user
        
    Returns:
        Current status and key metrics
    """
    try:
        asset = db.query(LoanAsset).filter(LoanAsset.id == asset_id).first()
        
        if not asset:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": "Loan asset not found"}
            )
        
        return {
            "status": "success",
            "asset_id": asset_id,
            "loan_id": asset.loan_id,
            "risk_status": asset.risk_status,
            "ndvi_score": asset.last_verified_score,
            "spt_threshold": asset.spt_threshold,
            "base_interest_rate": asset.base_interest_rate,
            "current_interest_rate": asset.current_interest_rate,
            "last_verified_at": asset.last_verified_at.isoformat() if asset.last_verified_at else None,
            "verification_error": asset.verification_error,
            "is_cdm_compliant": asset.spt_data is not None
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting audit status for asset {asset_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to get audit status: {str(e)}"}
        )


@router.get("/loan-assets/demo")
async def demo_loan_asset(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Get or create a demo loan asset for testing.
    
    Uses the Paradise, CA forest area as a demo location.
    """
    try:
        # Check if demo asset exists
        demo_asset = db.query(LoanAsset).filter(LoanAsset.loan_id == "DEMO-2024-001").first()
        
        if demo_asset:
            return {
                "status": "success",
                "message": "Demo asset already exists",
                "loan_asset": demo_asset.to_dict()
            }
        
        # Create demo asset
        from app.agents.audit_workflow import DEMO_COVENANT, run_full_audit
        
        result = await run_full_audit(
            loan_id="DEMO-2024-001",
            document_text=DEMO_COVENANT,
            db_session=db
        )
        
        return {
            "status": "success",
            "message": "Demo asset created",
            "loan_asset": result.loan_asset.to_dict() if result.loan_asset else None,
            "audit": {
                "success": result.success,
                "stages_completed": result.stages_completed,
                "stages_failed": result.stages_failed
            }
        }
        
    except Exception as e:
        db.rollback()
        logger.error(f"Error creating demo asset: {e}")
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to create demo asset: {str(e)}"}
        )

# ------------------------------------------------------------------------------
# Ground Truth Protocol - "Kill Shot" Demo Endpoints
# ------------------------------------------------------------------------------

@router.get("/cdm/events/{trade_id}")
async def get_cdm_events(trade_id: str):
    """
    Returns the Life-Cycle Events for the trade in FINOS CDM format.
    Includes the 'TermsChange' event triggered by the satellite observation.
    """
    # 1. Trade Execution (State v1)
    execution = generate_cdm_trade_execution(
        trade_id=trade_id,
        borrower="Napa Valley Vineyards LLC",
        amount=50000000.00,
        rate=5.00
    )
    
    # 2. Observation (The Satellite Signal) - Hardcoded 'BREACH' for demo storytelling
    # In a real sync workflow, this would come from the database
    mock_hash = hashlib.sha256(b"sentinel_2_image_patch_2024_08_15").hexdigest()
    observation = generate_cdm_observation(
        trade_id=trade_id,
        satellite_hash=mock_hash,
        ndvi_score=0.65,
        status="BREACH"
    )
    
    # 3. Terms Change (State v2) - The Financial Consequence
    terms_change = generate_cdm_terms_change(
        trade_id=trade_id,
        current_rate=5.00,
        status="BREACH"
    )
    
    # ---------------------------------------------------------
    # INFRASTRUCTURE LAYER: Vector Indexing (Side Effect)
    # ---------------------------------------------------------
    GLOBAL_VECTOR_STORE.add_trade_event(execution)
    GLOBAL_VECTOR_STORE.add_trade_event(observation)
    GLOBAL_VECTOR_STORE.add_trade_event(terms_change)
    
    return [execution, observation, terms_change]

@router.get("/search")
async def semantic_search_trades(q: str):
    """
    Semantic Search over Trade Lifecycle Events.
    Demonstrates "Hybrid Search" capabilities.
    """
    results = GLOBAL_VECTOR_STORE.semantic_search(q)
    return results

@router.post("/classify")
async def classify_land_use(lat: float, lon: float):
    """
    Real-time Deep Learning Inference using TorchGeo.
    """
    if not GLOBAL_CLASSIFIER:
        raise HTTPException(status_code=503, detail="Classifier not initialized")
        
    result = GLOBAL_CLASSIFIER.classify_lat_lon(lat, lon)
    return result


class TermsChangeRequest(BaseModel):
    """Request model for terms change with policy evaluation."""
    trade_id: str = Field(..., description="Trade identifier")
    current_rate: float = Field(..., ge=0, description="Current interest rate")
    proposed_rate: float = Field(..., ge=0, description="Proposed new interest rate")
    reason: str = Field(..., description="Reason for terms change")


@router.post("/trades/{trade_id}/terms-change")
async def change_trade_terms(
    trade_id: str,
    terms_request: TermsChangeRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
    policy_service: Optional[PolicyService] = Depends(get_policy_service)
):
    """
    Change trade terms (interest rate) with policy evaluation.
    
    This endpoint:
    1. Evaluates the proposed rate change against compliance policies
    2. Blocks, flags, or allows the rate change based on policy decision
    3. Generates CDM TermsChange event if allowed
    4. Returns the terms change result with policy decision
    
    Args:
        trade_id: Trade identifier (from path)
        terms_request: Terms change request with current/proposed rates
        db: Database session
        current_user: Current authenticated user
        policy_service: Policy service for compliance evaluation (optional)
        
    Returns:
        Terms change result with policy decision and CDM events
    """
    from app.models.cdm_events import generate_cdm_terms_change
    from app.db.models import PolicyDecision as PolicyDecisionModel
    
    try:
        # Validate trade_id matches request
        if terms_request.trade_id != trade_id:
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": "Trade ID in path must match trade_id in request body"}
            )
        
        logger.info(
            f"Terms change request: trade_id={trade_id}, "
            f"current_rate={terms_request.current_rate}, "
            f"proposed_rate={terms_request.proposed_rate}, "
            f"reason={terms_request.reason}"
        )
        
        # Calculate rate delta
        rate_delta = terms_request.proposed_rate - terms_request.current_rate
        
        # Policy evaluation (if enabled)
        policy_decision = None
        policy_evaluation_event = None
        
        if policy_service:
            try:
                # Evaluate terms change for compliance
                policy_result = policy_service.evaluate_terms_change(
                    trade_id=trade_id,
                    current_rate=terms_request.current_rate,
                    proposed_rate=terms_request.proposed_rate,
                    reason=terms_request.reason
                )
                
                # Create CDM PolicyEvaluation event
                from app.models.cdm_events import generate_cdm_policy_evaluation
                policy_evaluation_event = generate_cdm_policy_evaluation(
                    transaction_id=trade_id,
                    transaction_type="terms_change",
                    decision=policy_result.decision,
                    rule_applied=policy_result.rule_applied,
                    related_event_identifiers=[],
                    evaluation_trace=policy_result.trace,
                    matched_rules=policy_result.matched_rules
                )
                
                # Handle BLOCK decision - prevent rate change
                if policy_result.decision == "BLOCK":
                    logger.warning(
                        f"Policy evaluation BLOCKED terms change: "
                        f"trade_id={trade_id}, current_rate={terms_request.current_rate}, "
                        f"proposed_rate={terms_request.proposed_rate}, rule={policy_result.rule_applied}, "
                        f"trace_id={policy_result.trace_id}"
                    )
                    
                    # Log policy decision to audit trail
                    policy_decision_db = PolicyDecisionModel(
                        transaction_id=f"terms_change_{trade_id}",
                        transaction_type="terms_change",
                        decision=policy_result.decision,
                        rule_applied=policy_result.rule_applied,
                        trace_id=policy_result.trace_id,
                        trace=policy_result.trace,
                        matched_rules=policy_result.matched_rules,
                        metadata={
                            "trade_id": trade_id,
                            "current_rate": terms_request.current_rate,
                            "proposed_rate": terms_request.proposed_rate,
                            "rate_delta": rate_delta,
                            "reason": terms_request.reason
                        },
                        cdm_events=[policy_evaluation_event],
                        user_id=current_user.id if current_user else None
                    )
                    db.add(policy_decision_db)
                    db.commit()
                    
                    return {
                        "status": "blocked",
                        "decision": "BLOCK",
                        "rule": policy_result.rule_applied,
                        "trace_id": policy_result.trace_id,
                        "message": f"Terms change blocked by compliance policy: {policy_result.rule_applied}",
                        "current_rate": terms_request.current_rate,
                        "proposed_rate": terms_request.proposed_rate,
                        "cdm_event": policy_evaluation_event
                    }
                
                # Handle FLAG decision - allow but mark for review
                elif policy_result.decision == "FLAG":
                    logger.info(
                        f"Policy evaluation FLAGGED terms change: "
                        f"trade_id={trade_id}, rule={policy_result.rule_applied}, "
                        f"trace_id={policy_result.trace_id}"
                    )
                    
                    # Log policy decision to audit trail
                    policy_decision_db = PolicyDecisionModel(
                        transaction_id=f"terms_change_{trade_id}",
                        transaction_type="terms_change",
                        decision=policy_result.decision,
                        rule_applied=policy_result.rule_applied,
                        trace_id=policy_result.trace_id,
                        trace=policy_result.trace,
                        matched_rules=policy_result.matched_rules,
                        metadata={
                            "trade_id": trade_id,
                            "current_rate": terms_request.current_rate,
                            "proposed_rate": terms_request.proposed_rate,
                            "rate_delta": rate_delta,
                            "reason": terms_request.reason,
                            "requires_review": True
                        },
                        cdm_events=[policy_evaluation_event],
                        user_id=current_user.id if current_user else None
                    )
                    db.add(policy_decision_db)
                    db.commit()
                    
                    policy_decision = {
                        "decision": policy_result.decision,
                        "rule_applied": policy_result.rule_applied,
                        "trace_id": policy_result.trace_id,
                        "requires_review": True
                    }
                
                # Handle ALLOW decision - log for audit
                else:
                    logger.debug(
                        f"Policy evaluation ALLOWED terms change: "
                        f"trade_id={trade_id}, trace_id={policy_result.trace_id}"
                    )
                    
                    # Log policy decision to audit trail
                    policy_decision_db = PolicyDecisionModel(
                        transaction_id=f"terms_change_{trade_id}",
                        transaction_type="terms_change",
                        decision=policy_result.decision,
                        rule_applied=policy_result.rule_applied,
                        trace_id=policy_result.trace_id,
                        trace=policy_result.trace,
                        matched_rules=policy_result.matched_rules,
                        metadata={
                            "trade_id": trade_id,
                            "current_rate": terms_request.current_rate,
                            "proposed_rate": terms_request.proposed_rate,
                            "rate_delta": rate_delta,
                            "reason": terms_request.reason
                        },
                        cdm_events=[policy_evaluation_event],
                        user_id=current_user.id if current_user else None
                    )
                    db.add(policy_decision_db)
                    db.commit()
                    
                    policy_decision = {
                        "decision": policy_result.decision,
                        "rule_applied": policy_result.rule_applied,
                        "trace_id": policy_result.trace_id
                    }
                    
            except Exception as e:
                # Log policy evaluation errors but don't block terms change
                logger.error(f"Policy evaluation failed for terms change: {e}", exc_info=True)
                # Continue with terms change even if policy evaluation fails
        
        # Generate CDM TermsChange event (if not blocked)
        # Determine status from reason or rate delta
        status = "BREACH" if "breach" in terms_request.reason.lower() else "COMPLIANT"
        
        terms_change_event = generate_cdm_terms_change(
            trade_id=trade_id,
            current_rate=terms_request.current_rate,
            status=status,
            policy_service=policy_service
        )
        
        # If policy blocked the change, terms_change_event will be None
        if terms_change_event is None:
            return {
                "status": "blocked",
                "message": "Terms change blocked by policy evaluation",
                "current_rate": terms_request.current_rate,
                "proposed_rate": terms_request.proposed_rate
            }
        
        # Return terms change result
        return {
            "status": "changed",
            "trade_id": trade_id,
            "current_rate": terms_request.current_rate,
            "new_rate": terms_request.proposed_rate,
            "rate_delta": rate_delta,
            "terms_change_event": terms_change_event,
            "policy_decision": policy_decision,
            "cdm_events": (
                [terms_change_event, policy_evaluation_event]
                if policy_evaluation_event
                else [terms_change_event]
            )
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error during terms change: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Terms change failed: {str(e)}"}
        )


# ------------------------------------------------------------------------------
# x402 Payment Integration - Helper Functions
# ------------------------------------------------------------------------------

def get_trade_execution(trade_id: str, db: Session) -> Optional[Dict[str, Any]]:
    """
    Get trade execution event by trade ID.
    
    This helper function retrieves trade execution events. In a production system,
    trades would be stored in a database. For now, we'll check if the trade
    was recently executed and stored in the vector store or generate it on-demand.
    
    Args:
        trade_id: Trade identifier
        db: Database session
        
    Returns:
        Trade execution CDM event dictionary or None if not found
    """
    # Check vector store for trade events
    try:
        # Search vector store for trade events
        results = GLOBAL_VECTOR_STORE.semantic_search(trade_id)
        for result in results:
            event = result.get("json", {})
            if event.get("eventType") == "TradeExecution":
                trade = event.get("trade", {})
                trade_identifier = trade.get("tradeIdentifier", {})
                assigned_ids = trade_identifier.get("assignedIdentifier", [])
                if assigned_ids:
                    event_trade_id = assigned_ids[0].get("identifier", {}).get("value", "")
                    if event_trade_id == trade_id:
                        return event
    except Exception as e:
        logger.warning(f"Error searching vector store for trade {trade_id}: {e}")
    
    # If not found, return None (caller should handle)
    return None


def get_party_by_id(party_id: str, db: Session, credit_agreement = None):
    """
    Get party by ID from credit agreement or database.
    
    Args:
        party_id: Party identifier (LEI or internal ID)
        db: Database session
        credit_agreement: Optional credit agreement to search
        
    Returns:
        CDM Party object or None if not found
    """
    from app.models.cdm import Party, CreditAgreement
    
    # First, try to find in provided credit agreement
    if credit_agreement and credit_agreement.parties:
        for party in credit_agreement.parties:
            if party.id == party_id or party.lei == party_id:
                return party
    
    # If not found, try to find in documents
    try:
        # Query documents for party information
        from app.db.models import Document, DocumentVersion
        
        documents = db.query(Document).join(DocumentVersion).filter(
            DocumentVersion.extracted_data.isnot(None)
        ).limit(10).all()
        
        for doc in documents:
            if doc.current_version_id:
                version = db.query(DocumentVersion).filter(
                    DocumentVersion.id == doc.current_version_id
                ).first()
                if version and version.extracted_data:
                    try:
                        agreement = CreditAgreement(**version.extracted_data)
                        if agreement.parties:
                            for party in agreement.parties:
                                if party.id == party_id or party.lei == party_id:
                                    return party
                    except Exception:
                        continue
    except Exception as e:
        logger.warning(f"Error querying database for party {party_id}: {e}")
    
    # If not found, create a minimal party object
    # This is a fallback for demo purposes
    return Party(
        id=party_id,
        name=party_id,  # Use ID as name if not found
        role="Unknown",
        lei=None
    )


def update_trade_status(trade_id: str, status: str, db: Session) -> None:
    """
    Update trade status in database or tracking system.
    
    In a production system, this would update a trades table.
    For now, we'll log the status change to the audit trail.
    
    Args:
        trade_id: Trade identifier
        status: New status (pending, confirmed, settled, etc.)
        db: Database session
    """
    try:
        # Log status change to audit trail
        from app.db.models import AuditLog, AuditAction
        from datetime import datetime
        
        audit_log = AuditLog(
            user_id=None,  # System action
            action=AuditAction.UPDATE,
            target_type="trade",
            target_id=None,  # No numeric ID for trades yet
            metadata={
                "trade_id": trade_id,
                "status": status,
                "updated_at": datetime.utcnow().isoformat()
            }
        )
        db.add(audit_log)
        db.commit()
        
        logger.info(f"Trade {trade_id} status updated to {status}")
    except Exception as e:
        logger.error(f"Error updating trade status: {e}")
        db.rollback()


def get_credit_agreement_for_loan(loan_id: str, db: Session):
    """
    Get credit agreement for a loan by loan_id.
    
    This helper function retrieves the credit agreement associated with a loan.
    It searches through documents to find the agreement that matches the loan_id.
    
    Args:
        loan_id: Loan identifier
        db: Database session
        
    Returns:
        CreditAgreement object or None if not found
    """
    from app.models.cdm import CreditAgreement
    from app.db.models import Document, DocumentVersion
    
    try:
        # First, try to find loan asset and get associated document
        loan_asset = db.query(LoanAsset).filter(LoanAsset.loan_id == loan_id).first()
        
        # If loan asset exists and has document reference, use it
        # (Note: LoanAsset model may not have document_id field yet)
        
        # Search documents for credit agreement matching loan_id
        # Check if loan_id matches deal_id or loan_identification_number in extracted_data
        documents = db.query(Document).join(DocumentVersion).filter(
            DocumentVersion.extracted_data.isnot(None)
        ).all()
        
        for doc in documents:
            if doc.current_version_id:
                version = db.query(DocumentVersion).filter(
                    DocumentVersion.id == doc.current_version_id
                ).first()
                if version and version.extracted_data:
                    try:
                        agreement = CreditAgreement(**version.extracted_data)
                        # Check if loan_id matches deal_id or loan_identification_number
                        if (agreement.deal_id == loan_id or 
                            agreement.loan_identification_number == loan_id or
                            (loan_asset and hasattr(loan_asset, 'original_text') and 
                             loan_id in (loan_asset.original_text or ""))):
                            return agreement
                    except Exception as e:
                        logger.debug(f"Error parsing credit agreement from document {doc.id}: {e}")
                        continue
        
        # If not found in documents, try to extract from loan asset's original_text
        if loan_asset and hasattr(loan_asset, 'original_text') and loan_asset.original_text:
            try:
                # Try to extract credit agreement from loan asset's document text
                from app.chains.extraction_chain import extract_data_smart
                result = extract_data_smart(text=loan_asset.original_text)
                if result and result.agreement:
                    return result.agreement
            except Exception as e:
                logger.warning(f"Error extracting credit agreement from loan asset text: {e}")
        
        return None
        
    except Exception as e:
        logger.error(f"Error getting credit agreement for loan {loan_id}: {e}")
        return None


class PaymentPayloadRequest(BaseModel):
    """Request model for x402 payment payload."""
    payment_payload: Dict[str, Any] = Field(..., description="x402 payment payload from client wallet")


@router.post("/trades/{trade_id}/settle")
async def settle_trade_with_payment(
    trade_id: str,
    payment_request: Optional[PaymentPayloadRequest] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
    payment_service: Optional[X402PaymentService] = Depends(get_x402_payment_service)
):
    """
    Settle trade with x402 payment.
    
    This endpoint:
    1. Retrieves the trade execution event
    2. Extracts parties and amount from CDM trade event
    3. Processes payment via x402 (request  verify  settle)
    4. Creates CDM PaymentEvent
    5. Updates trade status to settled
    
    Args:
        trade_id: Trade identifier
        payment_request: Optional x402 payment payload (if None, returns 402 Payment Required)
        db: Database session
        current_user: Current authenticated user
        payment_service: x402 payment service (optional)
        
    Returns:
        Settlement result with payment confirmation or 402 Payment Required
    """
    from app.models.cdm import Party, Money, Currency
    from app.models.cdm_payment import PaymentEvent, PaymentType, PaymentMethod, PaymentStatus
    from app.db.models import PaymentEvent as PaymentEventModel
    from fastapi.responses import JSONResponse
    
    try:
        # Step 1: Get trade execution event
        trade_event = get_trade_execution(trade_id, db)
        
        if not trade_event:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": f"Trade {trade_id} not found"}
            )
        
        # Step 2: Extract parties and amount from CDM trade event
        try:
            trade = trade_event.get("trade", {})
            tradable_product = trade.get("tradableProduct", {})
            counterparties = tradable_product.get("counterparty", [])
            
            if len(counterparties) < 2:
                raise HTTPException(
                    status_code=400,
                    detail={"status": "error", "message": "Trade event missing counterparty information"}
                )
            
            # Extract payer and receiver from counterparties
            payer_ref = counterparties[0].get("partyReference", {}).get("globalReference", "")
            receiver_ref = counterparties[1].get("partyReference", {}).get("globalReference", "")
            
            # Extract amount and currency
            economic_terms = tradable_product.get("economicTerms", {})
            notional = economic_terms.get("notional", {})
            amount_value = notional.get("amount", {}).get("value", 0)
            currency_value = notional.get("currency", {}).get("value", "USD")
            
            amount = Decimal(str(amount_value))
            currency = Currency(currency_value)
            
        except (KeyError, ValueError, TypeError) as e:
            logger.error(f"Error parsing trade event: {e}")
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": f"Invalid trade event structure: {str(e)}"}
            )
        
        # Step 3: Get parties from CDM
        payer = get_party_by_id(payer_ref, db)
        receiver = get_party_by_id(receiver_ref, db)
        
        if not payer or not receiver:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": "Party information not found"}
            )
        
        # Step 4: Process payment via x402
        if not payment_service:
            raise HTTPException(
                status_code=503,
                detail={"status": "error", "message": "x402 payment service is not available"}
            )
        
        payment_payload = payment_request.payment_payload if payment_request else None
        
        payment_result = await payment_service.process_payment_flow(
            amount=amount,
            currency=currency,
            payer=payer,
            receiver=receiver,
            payment_type="trade_settlement",
            payment_payload=payment_payload,
            cdm_reference={
                "trade_id": trade_id,
                "event_type": "TradeExecution"
            }
        )
        
        # Step 5: Handle payment required (402 response)
        if payment_payload is None or payment_result.get("status") != "settled":
            return JSONResponse(
                status_code=402,
                content={
                    "status": "Payment Required",
                    "payment_request": payment_result.get("payment_request"),
                    "amount": str(amount),
                    "currency": currency.value,
                    "payer": {
                        "id": payer.id,
                        "name": payer.name,
                        "lei": payer.lei
                    },
                    "receiver": {
                        "id": receiver.id,
                        "name": receiver.name,
                        "lei": receiver.lei
                    },
                    "facilitator_url": payment_service.facilitator_url
                }
            )
        
        # Step 6: Create CDM PaymentEvent using CDM-compliant factory method
        payment_event = PaymentEvent.from_cdm_party(
            payer=payer,
            receiver=receiver,
            amount=Money(amount=amount, currency=currency),
            payment_type=PaymentType.TRADE_SETTLEMENT,
            payment_method=PaymentMethod.X402,
            trade_id=trade_id
        )
        
        # Step 7: Update with x402 payment details
        payment_event = payment_event.model_copy(update={
            "x402PaymentDetails": {
                "payment_payload": payment_payload,
                "verification": payment_result.get("verification"),
                "settlement": payment_result.get("settlement")
            },
            "transactionHash": payment_result.get("transaction_hash")
        })
        
        # Step 8: Transition through state machine: PENDING -> VERIFIED -> SETTLED
        payment_event = payment_event.transition_to_verified()
        payment_event = payment_event.transition_to_settled(payment_result.get("transaction_hash", ""))
        
        # Step 9: Save payment event to database
        payment_event_db = PaymentEventModel(
            payment_id=payment_event.paymentIdentifier.assignedIdentifier[0]["identifier"]["value"],
            payment_method=payment_event.paymentMethod.value,
            payment_type=payment_event.paymentType.value,
            payer_id=payment_event.payerPartyReference.globalReference,
            payer_name=payer.name,
            receiver_id=payment_event.receiverPartyReference.globalReference,
            receiver_name=receiver.name,
            amount=payment_event.paymentAmount.amount,
            currency=payment_event.paymentAmount.currency.value,
            status=payment_event.paymentStatus.value,
            x402_payment_payload=payment_payload,
            x402_verification=payment_result.get("verification"),
            x402_settlement=payment_result.get("settlement"),
            transaction_hash=payment_result.get("transaction_hash"),
            related_trade_id=trade_id,
            cdm_event=payment_event.to_cdm_json(),
            settled_at=datetime.utcnow()
        )
        db.add(payment_event_db)
        db.commit()
        
        # Step 10: Update trade status
        update_trade_status(trade_id, "settled", db)
        
        # Step 11: Log audit action
        log_audit_action(
            db=db,
            action=AuditAction.UPDATE,
            target_type="trade",
            target_id=None,
            user_id=current_user.id if current_user else None,
            metadata={
                "trade_id": trade_id,
                "status": "settled",
                "payment_id": payment_event_db.payment_id,
                "transaction_hash": payment_result.get("transaction_hash")
            },
            request=None
        )
        
        logger.info(f"Trade {trade_id} settled with payment {payment_event_db.payment_id}")
        
        return {
            "status": "success",
            "trade_id": trade_id,
            "payment": payment_event.to_cdm_json(),
            "settlement": payment_result,
            "payment_id": payment_event_db.payment_id,
            "transaction_hash": payment_result.get("transaction_hash")
        }
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Unexpected error during trade settlement: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Trade settlement failed: {str(e)}"}
        )


@router.post("/loans/{loan_id}/disburse")
async def disburse_loan_with_payment(
    loan_id: str,
    payment_request: Optional[PaymentPayloadRequest] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
    payment_service: Optional[X402PaymentService] = Depends(get_x402_payment_service)
):
    """
    Disburse loan with x402 payment verification.
    
    Requires payment before disbursing loan funds. Returns 402 Payment Required
    if payment payload is not provided.
    
    This endpoint:
    1. Gets loan asset and credit agreement
    2. Extracts borrower and lender parties
    3. Calculates disbursement amount from facilities
    4. Processes payment via x402 (lender pays borrower)
    5. Creates CDM PaymentEvent
    6. Updates loan asset disbursement status
    
    Args:
        loan_id: Loan identifier
        payment_request: Optional x402 payment payload
        db: Database session
        current_user: Current authenticated user
        payment_service: x402 payment service (optional)
        
    Returns:
        Disbursement result or 402 Payment Required response
    """
    from app.models.cdm import Party, Money, Currency
    from app.models.cdm_payment import PaymentEvent, PaymentType, PaymentMethod
    from app.db.models import PaymentEvent as PaymentEventModel
    from fastapi.responses import JSONResponse
    
    try:
        # Step 1: Get loan asset
        loan_asset = db.query(LoanAsset).filter(LoanAsset.loan_id == loan_id).first()
        
        if not loan_asset:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": f"Loan {loan_id} not found"}
            )
        
        # Step 2: Get credit agreement
        credit_agreement = get_credit_agreement_for_loan(loan_id, db)
        
        if not credit_agreement:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": f"Credit agreement not found for loan {loan_id}"}
            )
        
        # Step 3: Extract borrower and lender from CDM
        borrower = None
        lender = None
        
        if credit_agreement.parties:
            for party in credit_agreement.parties:
                role_lower = party.role.lower()
                if "borrower" in role_lower:
                    borrower = party
                elif "lender" in role_lower or "creditor" in role_lower:
                    lender = party
        
        if not borrower or not lender:
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": "Missing borrower or lender in credit agreement"}
            )
        
        # Step 4: Calculate disbursement amount
        total_commitment = Decimal("0")
        currency = Currency.USD
        
        if credit_agreement.facilities:
            for facility in credit_agreement.facilities:
                if facility.commitment_amount:
                    total_commitment += facility.commitment_amount.amount
                    if not currency:
                        currency = facility.commitment_amount.currency
        
        if total_commitment <= 0:
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": "No commitment amount found in facilities"}
            )
        
        # Step 5: Process payment via x402 (lender disburses to borrower)
        if not payment_service:
            raise HTTPException(
                status_code=503,
                detail={"status": "error", "message": "x402 payment service is not available"}
            )
        
        payment_payload = payment_request.payment_payload if payment_request else None
        
        payment_result = await payment_service.process_payment_flow(
            amount=total_commitment,
            currency=currency,
            payer=lender,  # Lender disburses to borrower
            receiver=borrower,
            payment_type="loan_disbursement",
            payment_payload=payment_payload,
            cdm_reference={
                "loan_id": loan_id,
                "credit_agreement_id": credit_agreement.deal_id or credit_agreement.loan_identification_number
            }
        )
        
        # Step 6: Handle payment required (402 response)
        if payment_payload is None or payment_result.get("status") != "settled":
            return JSONResponse(
                status_code=402,
                content={
                    "status": "Payment Required",
                    "payment_request": payment_result.get("payment_request"),
                    "amount": str(total_commitment),
                    "currency": currency.value,
                    "payer": {
                        "id": lender.id,
                        "name": lender.name,
                        "lei": lender.lei
                    },
                    "receiver": {
                        "id": borrower.id,
                        "name": borrower.name,
                        "lei": borrower.lei
                    },
                    "facilitator_url": payment_service.facilitator_url,
                    "loan_id": loan_id
                }
            )
        
        # Step 7: Create CDM PaymentEvent using CDM-compliant factory method
        payment_event = PaymentEvent.from_cdm_party(
            payer=lender,
            receiver=borrower,
            amount=Money(amount=total_commitment, currency=currency),
            payment_type=PaymentType.LOAN_DISBURSEMENT,
            payment_method=PaymentMethod.X402
        )
        
        # Step 8: Update with loan and facility references
        facility_id = None
        if credit_agreement.facilities and len(credit_agreement.facilities) > 0:
            facility_id = credit_agreement.facilities[0].facility_name or credit_agreement.facilities[0].facility_type
        
        payment_event = payment_event.model_copy(update={
            "relatedLoanId": loan_id,
            "relatedFacilityId": facility_id,
            "x402PaymentDetails": {
                "payment_payload": payment_payload,
                "settlement": payment_result.get("settlement")
            },
            "transactionHash": payment_result.get("transaction_hash")
        })
        
        # Step 9: Transition through state machine: PENDING -> VERIFIED -> SETTLED
        payment_event = payment_event.transition_to_verified()
        payment_event = payment_event.transition_to_settled(payment_result.get("transaction_hash", ""))
        
        # Step 10: Save payment event to database
        payment_event_db = PaymentEventModel(
            payment_id=payment_event.paymentIdentifier.assignedIdentifier[0]["identifier"]["value"],
            payment_method=payment_event.paymentMethod.value,
            payment_type=payment_event.paymentType.value,
            payer_id=payment_event.payerPartyReference.globalReference,
            payer_name=lender.name,
            receiver_id=payment_event.receiverPartyReference.globalReference,
            receiver_name=borrower.name,
            amount=payment_event.paymentAmount.amount,
            currency=payment_event.paymentAmount.currency.value,
            status=payment_event.paymentStatus.value,
            x402_payment_payload=payment_payload,
            x402_verification=payment_result.get("verification"),
            x402_settlement=payment_result.get("settlement"),
            transaction_hash=payment_result.get("transaction_hash"),
            related_loan_id=loan_id,
            related_facility_id=facility_id,
            cdm_event=payment_event.to_cdm_json(),
            settled_at=datetime.utcnow()
        )
        db.add(payment_event_db)
        
        # Step 11: Update loan asset disbursement status
        # Note: LoanAsset model may need disbursement_status and disbursement_date fields
        # For now, we'll log it in asset_metadata
        if hasattr(loan_asset, 'asset_metadata'):
            if loan_asset.asset_metadata is None:
                loan_asset.asset_metadata = {}
            loan_asset.asset_metadata["disbursement_status"] = "disbursed"
            loan_asset.asset_metadata["disbursement_date"] = datetime.utcnow().isoformat()
            loan_asset.asset_metadata["disbursement_amount"] = str(total_commitment)
            loan_asset.asset_metadata["disbursement_currency"] = currency.value
            loan_asset.asset_metadata["payment_id"] = payment_event_db.payment_id
        
        db.commit()
        
        # Step 12: Log audit action
        log_audit_action(
            db=db,
            action=AuditAction.UPDATE,
            target_type="loan_asset",
            target_id=loan_asset.id,
            user_id=current_user.id if current_user else None,
            metadata={
                "loan_id": loan_id,
                "action": "disbursement",
                "amount": str(total_commitment),
                "currency": currency.value,
                "payment_id": payment_event_db.payment_id,
                "transaction_hash": payment_result.get("transaction_hash")
            },
            request=None
        )
        
        logger.info(f"Loan {loan_id} disbursed with payment {payment_event_db.payment_id}")
        
        return {
            "status": "success",
            "loan_id": loan_id,
            "disbursement_amount": str(total_commitment),
            "currency": currency.value,
            "payment": payment_event.to_cdm_json(),
            "payment_id": payment_event_db.payment_id,
            "transaction_hash": payment_result.get("transaction_hash")
        }
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Unexpected error during loan disbursement: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Loan disbursement failed: {str(e)}"}
        )


@router.post("/loans/{loan_id}/penalty-payment")
async def penalty_payment(
    loan_id: str,
    payment_request: Optional[PaymentPayloadRequest] = None,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
    payment_service: Optional[X402PaymentService] = Depends(get_x402_payment_service)
):
    """
    Process penalty payment for loan breach.
    
    When a loan asset breaches its sustainability targets (NDVI below threshold),
    a penalty payment is required. This endpoint processes the penalty payment via x402.
    
    Args:
        loan_id: Loan identifier
        payment_request: Optional x402 payment payload
        db: Database session
        current_user: Current authenticated user
        payment_service: x402 payment service (optional)
        
    Returns:
        Penalty payment result or 402 Payment Required response
    """
    from app.models.cdm import Party, Money, Currency
    from app.models.cdm_payment import PaymentEvent, PaymentType, PaymentMethod
    from app.db.models import PaymentEvent as PaymentEventModel
    from fastapi.responses import JSONResponse
    
    try:
        # Step 1: Get loan asset
        loan_asset = db.query(LoanAsset).filter(LoanAsset.loan_id == loan_id).first()
        
        if not loan_asset:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": f"Loan {loan_id} not found"}
            )
        
        # Step 2: Verify breach status
        if loan_asset.risk_status != RiskStatus.BREACH:
            raise HTTPException(
                status_code=400,
                detail={
                    "status": "error",
                    "message": f"Loan {loan_id} is not in breach status. Current status: {loan_asset.risk_status}"
                }
            )
        
        # Step 3: Get credit agreement
        credit_agreement = get_credit_agreement_for_loan(loan_id, db)
        
        if not credit_agreement:
            raise HTTPException(
                status_code=404,
                detail={"status": "error", "message": f"Credit agreement not found for loan {loan_id}"}
            )
        
        # Step 4: Extract borrower and lender
        borrower = None
        lender = None
        
        if credit_agreement.parties:
            for party in credit_agreement.parties:
                role_lower = party.role.lower()
                if "borrower" in role_lower:
                    borrower = party
                elif "lender" in role_lower or "creditor" in role_lower:
                    lender = party
        
        if not borrower or not lender:
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": "Missing borrower or lender in credit agreement"}
            )
        
        # Step 5: Calculate penalty amount
        # Penalty is calculated based on penalty_bps and principal amount
        if not credit_agreement.facilities or not credit_agreement.facilities[0].commitment_amount:
            raise HTTPException(
                status_code=400,
                detail={"status": "error", "message": "No commitment amount found in facilities"}
            )
        
        facility = credit_agreement.facilities[0]
        principal = facility.commitment_amount.amount
        currency = facility.commitment_amount.currency
        
        # Calculate penalty: principal * (penalty_bps / 10000)
        penalty_bps = loan_asset.penalty_bps or 50.0  # Default 50 bps
        penalty_amount = principal * (Decimal(str(penalty_bps)) / Decimal("10000"))
        
        # Step 6: Process payment via x402 (borrower pays lender penalty)
        if not payment_service:
            raise HTTPException(
                status_code=503,
                detail={"status": "error", "message": "x402 payment service is not available"}
            )
        
        payment_payload = payment_request.payment_payload if payment_request else None
        
        payment_result = await payment_service.process_payment_flow(
            amount=penalty_amount,
            currency=currency,
            payer=borrower,  # Borrower pays penalty to lender
            receiver=lender,
            payment_type="penalty_payment",
            payment_payload=payment_payload,
            cdm_reference={
                "loan_id": loan_id,
                "breach_ndvi_score": loan_asset.last_verified_score,
                "penalty_bps": penalty_bps
            }
        )
        
        # Step 7: Handle payment required (402 response)
        if payment_payload is None or payment_result.get("status") != "settled":
            return JSONResponse(
                status_code=402,
                content={
                    "status": "Payment Required",
                    "payment_request": payment_result.get("payment_request"),
                    "amount": str(penalty_amount),
                    "currency": currency.value,
                    "penalty_bps": penalty_bps,
                    "payer": {
                        "id": borrower.id,
                        "name": borrower.name,
                        "lei": borrower.lei
                    },
                    "receiver": {
                        "id": lender.id,
                        "name": lender.name,
                        "lei": lender.lei
                    },
                    "facilitator_url": payment_service.facilitator_url,
                    "loan_id": loan_id,
                    "breach_reason": f"NDVI score {loan_asset.last_verified_score} below threshold {loan_asset.spt_threshold}"
                }
            )
        
        # Step 8: Create CDM PaymentEvent
        payment_event = PaymentEvent.from_cdm_party(
            payer=borrower,
            receiver=lender,
            amount=Money(amount=penalty_amount, currency=currency),
            payment_type=PaymentType.PENALTY_PAYMENT,
            payment_method=PaymentMethod.X402
        )
        
        # Update with loan and breach information
        facility_id = None
        if credit_agreement.facilities and len(credit_agreement.facilities) > 0:
            facility_id = credit_agreement.facilities[0].facility_name or credit_agreement.facilities[0].facility_type
        
        payment_event = payment_event.model_copy(update={
            "relatedLoanId": loan_id,
            "relatedFacilityId": facility_id,
            "x402PaymentDetails": {
                "payment_payload": payment_payload,
                "settlement": payment_result.get("settlement"),
                "breach_ndvi_score": loan_asset.last_verified_score,
                "penalty_bps": penalty_bps
            },
            "transactionHash": payment_result.get("transaction_hash")
        })
        
        # Step 9: Transition through state machine
        payment_event = payment_event.transition_to_verified()
        payment_event = payment_event.transition_to_settled(payment_result.get("transaction_hash", ""))
        
        # Step 10: Save payment event to database
        payment_event_db = PaymentEventModel(
            payment_id=payment_event.paymentIdentifier.assignedIdentifier[0]["identifier"]["value"],
            payment_method=payment_event.paymentMethod.value,
            payment_type=payment_event.paymentType.value,
            payer_id=payment_event.payerPartyReference.globalReference,
            payer_name=borrower.name,
            receiver_id=payment_event.receiverPartyReference.globalReference,
            receiver_name=lender.name,
            amount=payment_event.paymentAmount.amount,
            currency=payment_event.paymentAmount.currency.value,
            status=payment_event.paymentStatus.value,
            x402_payment_payload=payment_payload,
            x402_verification=payment_result.get("verification"),
            x402_settlement=payment_result.get("settlement"),
            transaction_hash=payment_result.get("transaction_hash"),
            related_loan_id=loan_id,
            related_facility_id=facility_id,
            cdm_event=payment_event.to_cdm_json(),
            settled_at=datetime.utcnow()
        )
        db.add(payment_event_db)
        
        # Step 11: Update loan asset metadata to mark penalty as paid
        if loan_asset.asset_metadata is None:
            loan_asset.asset_metadata = {}
        loan_asset.asset_metadata["penalty_payment_required"] = False
        loan_asset.asset_metadata["penalty_payment_paid"] = True
        loan_asset.asset_metadata["penalty_payment_id"] = payment_event_db.payment_id
        loan_asset.asset_metadata["penalty_payment_date"] = datetime.utcnow().isoformat()
        loan_asset.asset_metadata["penalty_amount"] = str(penalty_amount)
        
        db.commit()
        
        # Step 12: Log audit action
        log_audit_action(
            db=db,
            action=AuditAction.UPDATE,
            target_type="loan_asset",
            target_id=loan_asset.id,
            user_id=current_user.id if current_user else None,
            metadata={
                "loan_id": loan_id,
                "action": "penalty_payment",
                "amount": str(penalty_amount),
                "currency": currency.value,
                "penalty_bps": penalty_bps,
                "payment_id": payment_event_db.payment_id,
                "transaction_hash": payment_result.get("transaction_hash"),
                "breach_ndvi_score": loan_asset.last_verified_score
            },
            request=None
        )
        
        logger.info(
            f"Penalty payment processed for loan {loan_id}: "
            f"payment_id={payment_event_db.payment_id}, "
            f"amount={penalty_amount}"
        )
        
        return {
            "status": "success",
            "loan_id": loan_id,
            "penalty_amount": str(penalty_amount),
            "currency": currency.value,
            "penalty_bps": penalty_bps,
            "payment": payment_event.to_cdm_json(),
            "payment_id": payment_event_db.payment_id,
            "transaction_hash": payment_result.get("transaction_hash"),
            "breach_ndvi_score": loan_asset.last_verified_score
        }
        
    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        logger.error(f"Unexpected error during penalty payment: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Penalty payment failed: {str(e)}"}
        )


@router.get("/policy/statistics")
async def get_policy_statistics(
    transaction_type: Optional[str] = Query(None, description="Filter by transaction type"),
    decision: Optional[str] = Query(None, description="Filter by decision (ALLOW, BLOCK, FLAG)"),
    start_date: Optional[str] = Query(None, description="Start date (ISO 8601 format)"),
    end_date: Optional[str] = Query(None, description="End date (ISO 8601 format)"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    Get aggregated policy decision statistics.
    
    Provides comprehensive statistics about policy evaluations including:
    - Total decisions processed
    - Counts by decision type (ALLOW, BLOCK, FLAG)
    - Top rules applied
    - Counts by transaction type
    - Time series data for charting
    
    Args:
        transaction_type: Optional filter by transaction type
        decision: Optional filter by decision
        start_date: Optional start date filter (ISO 8601)
        end_date: Optional end date filter (ISO 8601)
        db: Database session
        current_user: Current authenticated user
        
    Returns:
        Dictionary with policy statistics
    """
    from app.services.policy_audit import get_policy_statistics as get_stats
    
    try:
        # Parse dates if provided
        start_dt = None
        end_dt = None
        
        if start_date:
            try:
                start_dt = datetime.fromisoformat(start_date.replace("Z", "+00:00"))
            except ValueError:
                raise HTTPException(
                    status_code=400,
                    detail={"status": "error", "message": f"Invalid start_date format: {start_date}. Use ISO 8601 format."}
                )
        
        if end_date:
            try:
                end_dt = datetime.fromisoformat(end_date.replace("Z", "+00:00"))
            except ValueError:
                raise HTTPException(
                    status_code=400,
                    detail={"status": "error", "message": f"Invalid end_date format: {end_date}. Use ISO 8601 format."}
                )
        
        # Get statistics
        stats = get_stats(
            db=db,
            start_date=start_dt,
            end_date=end_dt,
            transaction_type=transaction_type
        )
        
        # Apply decision filter if provided
        if decision:
            decision_upper = decision.upper()
            if decision_upper not in ["ALLOW", "BLOCK", "FLAG"]:
                raise HTTPException(
                    status_code=400,
                    detail={"status": "error", "message": f"Invalid decision: {decision}. Must be ALLOW, BLOCK, or FLAG."}
                )
            # Filter time series and other data by decision
            # Note: The statistics function already aggregates by decision,
            # so we just return the filtered decision count
            stats["decisions"] = {decision_upper: stats["decisions"].get(decision_upper, 0)}
        
        return {
            "status": "success",
            "statistics": stats
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to get policy statistics: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to get policy statistics: {str(e)}"}
        )


@router.get("/policy/decisions")
async def list_policy_decisions(
    transaction_id: Optional[str] = Query(None, description="Filter by transaction ID"),
    transaction_type: Optional[str] = Query(None, description="Filter by transaction type"),
    decision: Optional[str] = Query(None, description="Filter by decision (ALLOW, BLOCK, FLAG)"),
    rule_applied: Optional[str] = Query(None, description="Filter by rule name"),
    start_date: Optional[str] = Query(None, description="Start date (ISO 8601 format)"),
    end_date: Optional[str] = Query(None, description="End date (ISO 8601 format)"),
    limit: int = Query(50, ge=1, le=100, description="Maximum number of results"),
    offset: int = Query(0, ge=0, description="Offset for pagination"),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    List policy decisions with filtering and pagination.
    
    Args:
        transaction_id: Filter by transaction ID
        transaction_type: Filter by transaction type
        decision: Filter by decision (ALLOW, BLOCK, FLAG)
        rule_applied: Filter by rule name
        start_date: Filter by start date (ISO 8601)
        end_date: Filter by end date (ISO 8601)
        limit: Maximum results (default 50, max 100)
        offset: Pagination offset
        db: Database session
        current_user: Current authenticated user
        
    Returns:
        List of policy decisions
    """
    from app.services.policy_audit import get_policy_decisions
    
    try:
        # Parse dates if provided
        start_dt = None
        end_dt = None
        
        if start_date:
            try:
                start_dt = datetime.fromisoformat(start_date.replace("Z", "+00:00"))
            except ValueError:
                raise HTTPException(
                    status_code=400,
                    detail={"status": "error", "message": f"Invalid start_date format: {start_date}"}
                )
        
        if end_date:
            try:
                end_dt = datetime.fromisoformat(end_date.replace("Z", "+00:00"))
            except ValueError:
                raise HTTPException(
                    status_code=400,
                    detail={"status": "error", "message": f"Invalid end_date format: {end_date}"}
                )
        
        # Get decisions
        decisions = get_policy_decisions(
            db=db,
            transaction_id=transaction_id,
            transaction_type=transaction_type,
            decision=decision,
            rule_applied=rule_applied,
            start_date=start_dt,
            end_date=end_dt,
            limit=limit,
            offset=offset
        )
        
        return {
            "status": "success",
            "total": len(decisions),
            "limit": limit,
            "offset": offset,
            "decisions": [decision.to_dict() for decision in decisions]
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to list policy decisions: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Failed to list policy decisions: {str(e)}"}
        )


@router.post("/trades/execute")
async def execute_trade(
    trade_request: TradeExecutionRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
    policy_service: Optional[PolicyService] = Depends(get_policy_service)
):
    """
    Execute a trade with policy evaluation.
    
    This endpoint:
    1. Generates a CDM TradeExecution event
    2. Evaluates the trade against compliance policies
    3. Blocks, flags, or allows the trade based on policy decision
    4. Returns the trade execution result with policy decision
    
    Args:
        trade_request: Trade execution request with trade details
        db: Database session
        current_user: Current authenticated user
        policy_service: Policy service for compliance evaluation (optional)
        
    Returns:
        Trade execution result with policy decision and CDM events
    """
    from app.models.cdm_events import generate_cdm_trade_execution
    from app.db.models import PolicyDecision as PolicyDecisionModel
    from app.models.cdm import CreditAgreement
    
    try:
        logger.info(
            f"Trade execution request: trade_id={trade_request.trade_id}, "
            f"borrower={trade_request.borrower}, amount={trade_request.amount}"
        )
        
        # Step 1: Generate CDM TradeExecution event
        trade_event = generate_cdm_trade_execution(
            trade_id=trade_request.trade_id,
            borrower=trade_request.borrower,
            amount=trade_request.amount,
            rate=trade_request.rate
        )
        
        # Step 2: Get credit agreement if provided
        credit_agreement = None
        if trade_request.credit_agreement_id:
            doc = db.query(Document).filter(Document.id == trade_request.credit_agreement_id).first()
            if doc and doc.current_version_id:
                version = db.query(DocumentVersion).filter(
                    DocumentVersion.id == doc.current_version_id
                ).first()
                if version and version.extracted_data:
                    try:
                        credit_agreement = CreditAgreement(**version.extracted_data)
                    except Exception as e:
                        logger.warning(f"Failed to parse credit agreement from document: {e}")
        
        # Step 3: Policy evaluation (if enabled)
        policy_decision = None
        policy_evaluation_event = None
        
        if policy_service:
            try:
                # Evaluate trade execution for compliance
                policy_result = policy_service.evaluate_trade_execution(
                    cdm_event=trade_event,
                    credit_agreement=credit_agreement
                )
                
                # Create CDM PolicyEvaluation event
                from app.models.cdm_events import generate_cdm_policy_evaluation
                policy_evaluation_event = generate_cdm_policy_evaluation(
                    transaction_id=trade_request.trade_id,
                    transaction_type="trade_execution",
                    decision=policy_result.decision,
                    rule_applied=policy_result.rule_applied,
                    related_event_identifiers=[{
                        "eventIdentifier": {
                            "issuer": "CreditNexus",
                            "assignedIdentifier": [{
                                "identifier": {"value": trade_event["meta"]["globalKey"]}
                            }]
                        }
                    }],
                    evaluation_trace=policy_result.trace,
                    matched_rules=policy_result.matched_rules
                )
                
                # Handle BLOCK decision - prevent trade execution
                if policy_result.decision == "BLOCK":
                    logger.warning(
                        f"Policy evaluation BLOCKED trade execution: "
                        f"trade_id={trade_request.trade_id}, rule={policy_result.rule_applied}, "
                        f"trace_id={policy_result.trace_id}"
                    )
                    
                    # Log policy decision to audit trail
                    policy_decision_db = PolicyDecisionModel(
                        transaction_id=trade_request.trade_id,
                        transaction_type="trade_execution",
                        decision=policy_result.decision,
                        rule_applied=policy_result.rule_applied,
                        trace_id=policy_result.trace_id,
                        trace=policy_result.trace,
                        matched_rules=policy_result.matched_rules,
                        metadata={"trade_execution": True},
                        cdm_events=[policy_evaluation_event],
                        user_id=current_user.id if current_user else None
                    )
                    db.add(policy_decision_db)
                    db.commit()
                    
                    return {
                        "status": "blocked",
                        "decision": "BLOCK",
                        "rule": policy_result.rule_applied,
                        "trace_id": policy_result.trace_id,
                        "message": f"Trade execution blocked by compliance policy: {policy_result.rule_applied}",
                        "cdm_event": policy_evaluation_event,
                        "trade_event": trade_event
                    }
                
                # Handle FLAG decision - allow but mark for review
                elif policy_result.decision == "FLAG":
                    logger.info(
                        f"Policy evaluation FLAGGED trade execution: "
                        f"trade_id={trade_request.trade_id}, rule={policy_result.rule_applied}, "
                        f"trace_id={policy_result.trace_id}"
                    )
                    
                    # Log policy decision to audit trail
                    policy_decision_db = PolicyDecisionModel(
                        transaction_id=trade_request.trade_id,
                        transaction_type="trade_execution",
                        decision=policy_result.decision,
                        rule_applied=policy_result.rule_applied,
                        trace_id=policy_result.trace_id,
                        trace=policy_result.trace,
                        matched_rules=policy_result.matched_rules,
                        metadata={"trade_execution": True, "requires_review": True},
                        cdm_events=[policy_evaluation_event],
                        user_id=current_user.id if current_user else None
                    )
                    db.add(policy_decision_db)
                    db.commit()
                    
                    policy_decision = {
                        "decision": policy_result.decision,
                        "rule_applied": policy_result.rule_applied,
                        "trace_id": policy_result.trace_id,
                        "requires_review": True
                    }
                
                # Handle ALLOW decision - log for audit
                else:
                    logger.debug(
                        f"Policy evaluation ALLOWED trade execution: "
                        f"trade_id={trade_request.trade_id}, trace_id={policy_result.trace_id}"
                    )
                    
                    # Log policy decision to audit trail
                    policy_decision_db = PolicyDecisionModel(
                        transaction_id=trade_request.trade_id,
                        transaction_type="trade_execution",
                        decision=policy_result.decision,
                        rule_applied=policy_result.rule_applied,
                        trace_id=policy_result.trace_id,
                        trace=policy_result.trace,
                        matched_rules=policy_result.matched_rules,
                        metadata={"trade_execution": True},
                        cdm_events=[policy_evaluation_event],
                        user_id=current_user.id if current_user else None
                    )
                    db.add(policy_decision_db)
                    db.commit()
                    
                    policy_decision = {
                        "decision": policy_result.decision,
                        "rule_applied": policy_result.rule_applied,
                        "trace_id": policy_result.trace_id
                    }
                    
            except Exception as e:
                # Log policy evaluation errors but don't block trade
                logger.error(f"Policy evaluation failed for trade {trade_request.trade_id}: {e}", exc_info=True)
                # Continue with trade execution even if policy evaluation fails
        
        # Step 4: Return trade execution result
        return {
            "status": "executed",
            "trade_id": trade_request.trade_id,
            "trade_event": trade_event,
            "policy_decision": policy_decision,
            "cdm_events": (
                [trade_event, policy_evaluation_event]
                if policy_evaluation_event
                else [trade_event]
            )
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error during trade execution: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail={"status": "error", "message": f"Trade execution failed: {str(e)}"}
        )


# ============================================================================
# LMA Template Generation API Endpoints
# ============================================================================

from app.templates.registry import TemplateRegistry
from app.generation.service import DocumentGenerationService
from app.db.models import LMATemplate, GeneratedDocument, TemplateFieldMapping


class GenerateDocumentRequest(BaseModel):
    """Request model for document generation."""
    template_id: int = Field(..., description="Template ID")
    cdm_data: dict = Field(..., description="CDM CreditAgreement data")
    source_document_id: Optional[int] = Field(None, description="Optional source document ID")


class ExportRequest(BaseModel):
    """Request model for document export."""
    format: str = Field(..., description="Export format: 'word' or 'pdf'")


@router.get("/templates")
async def list_templates(
    category: Optional[str] = Query(None, description="Filter by template category"),
    subcategory: Optional[str] = Query(None, description="Filter by subcategory"),
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """
    List available LMA templates.
    
    Args:
        category: Optional category filter
        subcategory: Optional subcategory filter
        db: Database session
        current_user: Authenticated user
        
    Returns:
        List of template metadata
    """
    try:
        templates = TemplateRegistry.list_templates(
            db,
            category,
            subcategory
        )
        
        return {
            "templates": [template.to_dict() for template in templates],
            "count": len(templates)
        }
    except Exception as e:
        logger.error(f"Error listing templates: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to list templates: {str(e)}")


@router.get("/templates/{template_id}")
async def get_template(
    template_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """
    Get template metadata by ID.
    
    Args:
        template_id: Template ID
        db: Database session
        current_user: Authenticated user
        
    Returns:
        Template metadata
    """
    try:
        template = TemplateRegistry.get_template(db, template_id)
        return template.to_dict()
    except Exception as e:
        logger.error(f"Error getting template {template_id}: {e}", exc_info=True)
        raise HTTPException(status_code=404, detail=f"Template not found: {str(e)}")


@router.get("/templates/{template_id}/requirements")
async def get_template_requirements(
    template_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """
    Get required CDM fields for a template.
    
    Args:
        template_id: Template ID
        db: Database session
        current_user: Authenticated user
        
    Returns:
        Dictionary with required and optional fields
    """
    try:
        template = TemplateRegistry.get_template(db, template_id)
        required_fields = TemplateRegistry.get_required_fields(template)
        
        return {
            "template_id": template_id,
            "template_code": template.template_code,
            "required_fields": required_fields,
            "optional_fields": template.optional_fields or [],
            "ai_generated_sections": template.ai_generated_sections or [],
        }
    except Exception as e:
        logger.error(f"Error getting template requirements {template_id}: {e}", exc_info=True)
        raise HTTPException(status_code=404, detail=f"Template not found: {str(e)}")


@router.get("/templates/{template_id}/mappings")
async def get_template_mappings(
    template_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """
    Get CDM field mappings for a template.
    
    Args:
        template_id: Template ID
        db: Database session
        current_user: Authenticated user
        
    Returns:
        List of field mappings
    """
    try:
        template = TemplateRegistry.get_template(db, template_id)
        mappings = TemplateRegistry.get_field_mappings(db, template_id)
        
        return {
            "template_id": template_id,
            "template_code": template.template_code,
            "mappings": [mapping.to_dict() for mapping in mappings],
            "count": len(mappings)
        }
    except Exception as e:
        logger.error(f"Error getting template mappings {template_id}: {e}", exc_info=True)
        raise HTTPException(status_code=404, detail=f"Template not found: {str(e)}")


@router.post("/templates/generate")
async def generate_document(
    request: GenerateDocumentRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """
    Generate a document from a template using CDM data.
    
    Args:
        request: GenerateDocumentRequest with template_id and cdm_data
        db: Database session
        current_user: Authenticated user
        
    Returns:
        Generated document metadata
    """
    try:
        # Parse CDM data
        try:
            cdm_agreement = CreditAgreement(**request.cdm_data)
        except Exception as e:
            raise HTTPException(
                status_code=400,
                detail=f"Invalid CDM data: {str(e)}"
            )
        
        # Generate document
        generation_service = DocumentGenerationService()
        generated_doc = generation_service.generate_document(
            db=db,
            template_id=request.template_id,
            cdm_data=cdm_agreement,
            user_id=current_user.id,
            source_document_id=request.source_document_id
        )
        
        return {
            "id": generated_doc.id,
            "template_id": generated_doc.template_id,
            "file_path": generated_doc.file_path,
            "status": generated_doc.status,
            "generation_summary": generated_doc.generation_summary,
            "created_at": generated_doc.created_at.isoformat() if generated_doc.created_at else None,
        }
        
    except ValueError as e:
        logger.error(f"Validation error during document generation: {e}", exc_info=True)
        raise HTTPException(status_code=400, detail=str(e))
    except IOError as e:
        logger.error(f"I/O error during document generation: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        logger.error(f"Unexpected error during document generation: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Document generation failed: {str(e)}")


@router.get("/generated-documents")
async def list_generated_documents(
    page: int = Query(1, ge=1, description="Page number"),
    limit: int = Query(20, ge=1, le=100, description="Items per page"),
    template_id: Optional[int] = Query(None, description="Filter by template ID"),
    status: Optional[str] = Query(None, description="Filter by status"),
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """
    List generated documents with pagination.
    
    Args:
        page: Page number (1-indexed)
        limit: Items per page
        template_id: Optional template ID filter
        status: Optional status filter
        db: Database session
        current_user: Authenticated user
        
    Returns:
        Paginated list of generated documents
    """
    try:
        query = db.query(GeneratedDocument)
        
        # Apply filters
        if template_id:
            query = query.filter(GeneratedDocument.template_id == template_id)
        if status:
            query = query.filter(GeneratedDocument.status == status)
        
        # Get total count
        total = query.count()
        
        # Apply pagination
        offset = (page - 1) * limit
        documents = query.order_by(GeneratedDocument.created_at.desc()).offset(offset).limit(limit).all()
        
        return {
            "documents": [doc.to_dict() for doc in documents],
            "pagination": {
                "page": page,
                "limit": limit,
                "total": total,
                "pages": (total + limit - 1) // limit
            }
        }
    except Exception as e:
        logger.error(f"Error listing generated documents: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to list documents: {str(e)}")


@router.get("/generated-documents/{document_id}")
async def get_generated_document(
    document_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """
    Get generated document details by ID.
    
    Args:
        document_id: Generated document ID
        db: Database session
        current_user: Authenticated user
        
    Returns:
        Generated document details
    """
    try:
        doc = db.query(GeneratedDocument).filter(GeneratedDocument.id == document_id).first()
        if not doc:
            raise HTTPException(status_code=404, detail=f"Generated document {document_id} not found")
        
        return doc.to_dict()
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting generated document {document_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Failed to get document: {str(e)}")


@router.post("/generated-documents/{document_id}/export")
async def export_generated_document(
    document_id: int,
    request: ExportRequest,
    db: Session = Depends(get_db),
    current_user: User = Depends(require_auth)
):
    """
    Export generated document as Word or PDF.
    
    Args:
        document_id: Generated document ID
        request: ExportRequest with format
        db: Database session
        current_user: Authenticated user
        
    Returns:
        File download response
    """
    try:
        from pathlib import Path
        from fastapi.responses import FileResponse
        
        doc = db.query(GeneratedDocument).filter(GeneratedDocument.id == document_id).first()
        if not doc:
            raise HTTPException(status_code=404, detail=f"Generated document {document_id} not found")
        
        if not doc.file_path:
            raise HTTPException(status_code=400, detail="Document file not found")
        
        file_path = Path(doc.file_path)
        if not file_path.exists():
            raise HTTPException(status_code=404, detail="Document file not found on disk")
        
        # For Word format, return as-is
        if request.format.lower() == "word":
            return FileResponse(
                path=str(file_path),
                filename=file_path.name,
                media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
        
        # For PDF, convert (if implemented)
        elif request.format.lower() == "pdf":
            # For now, raise NotImplementedError
            # In production, implement PDF conversion
            raise HTTPException(
                status_code=501,
                detail="PDF export not yet implemented. Use Word format for now."
            )
        else:
            raise HTTPException(status_code=400, detail=f"Unsupported format: {request.format}")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error exporting document {document_id}: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Export failed: {str(e)}")

